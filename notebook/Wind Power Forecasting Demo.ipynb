{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "from Losses import *\n",
    "from Metrics import evaluate, cross_bound_check\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataLoader:\n",
    "    def __init__(self, data, window_size, label_column, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, scaler=None):\n",
    "        self.data         = data\n",
    "        self.window_size  = window_size\n",
    "        self.label_column = label_column\n",
    "        self.train_ratio  = train_ratio\n",
    "        self.val_ratio    = val_ratio\n",
    "        self.test_ratio   = test_ratio\n",
    "        self.scaler       = scaler\n",
    "\n",
    "        self.train_X, self.train_y = None, None\n",
    "        self.val_X, self.val_y = None, None\n",
    "        self.test_X, self.test_y = None, None\n",
    "\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        # 删除缺失值\n",
    "        self.data = self.data.dropna()\n",
    "\n",
    "        # 划分特征和目标变量\n",
    "        X = self.data.drop(columns=[self.label_column]).values\n",
    "        y = self.data[self.label_column].values\n",
    "\n",
    "        # 处理缺失值（如果有）\n",
    "        # 进行标准化（如果需要）\n",
    "        if self.scaler is None:\n",
    "            self.scaler_x = StandardScaler()\n",
    "            self.scaler_y = StandardScaler()\n",
    "            X = self.scaler_x.fit_transform(X)\n",
    "            y = self.scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "        data = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
    "        # 生成窗口数据\n",
    "        sequences_X, sequences_y = [], []\n",
    "        for i in range(len(self.data) - self.window_size + 1):\n",
    "            window_X = data[i:i + self.window_size]\n",
    "            window_y = y[i + self.window_size - 1]  # 取窗口最后一个样本作为目标变量\n",
    "            sequences_X.append(window_X)\n",
    "            sequences_y.append(window_y)\n",
    "        sequences_X, sequences_y = np.array(sequences_X), np.array(sequences_y)\n",
    "        # print(f'x: {sequences_X.shape}, y: {sequences_y.shape}')\n",
    "        # sequences_X = np.concatenate((sequences_X, sequences_y.reshape(-1, 1)), axis=1)\n",
    "        sequences_X = sequences_X.reshape(len(sequences_X), self.window_size*sequences_X.shape[2])\n",
    "\n",
    "        # 划分训练集、验证集、测试集\n",
    "        train_size = int(len(sequences_X) * self.train_ratio)\n",
    "        val_size = int(len(sequences_X) * self.val_ratio)\n",
    "        test_size = len(sequences_X) - train_size - val_size\n",
    "\n",
    "        self.train_X, self.train_y = sequences_X[:train_size], sequences_y[:train_size]\n",
    "        self.val_X, self.val_y = sequences_X[train_size:train_size + val_size], sequences_y[train_size:train_size + val_size]\n",
    "        self.test_X, self.test_y = sequences_X[train_size + val_size:], sequences_y[train_size + val_size:]\n",
    "\n",
    "    def inverse_transform(self, data, is_label=True):\n",
    "        # 将标准化后的数据还原\n",
    "        if is_label:\n",
    "            if data.ndim < 2:\n",
    "                return self.scaler_y.inverse_transform(data.reshape(-1, 1)).flatten()\n",
    "            else:\n",
    "                for i in range(data.shape[1]):\n",
    "                    data[:, i] = self.scaler_y.inverse_transform(data[:, i].reshape(-1, 1)).flatten()\n",
    "                return data\n",
    "        else:\n",
    "            return self.scaler_x.inverse_transform(data)\n",
    "\n",
    "    def get_train_data(self, to_tensor=False):\n",
    "        if to_tensor:\n",
    "            return torch.from_numpy(self.train_X).to(torch.float32), torch.from_numpy(self.train_y).to(torch.float32)\n",
    "        else:\n",
    "            return self.train_X, self.train_y\n",
    "\n",
    "    def get_val_data(self, to_tensor=False):\n",
    "        if to_tensor:\n",
    "            return torch.from_numpy(self.val_X).to(torch.float32), torch.from_numpy(self.val_y).to(torch.float32)\n",
    "        else:\n",
    "            return self.val_X, self.val_y\n",
    "\n",
    "    def get_test_data(self, to_tensor=False):\n",
    "        if to_tensor:\n",
    "            return torch.from_numpy(self.test_X).to(torch.float32), torch.from_numpy(self.test_y).to(torch.float32)\n",
    "        else:\n",
    "            return self.test_X, self.test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActivePower</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDirection_sin</th>\n",
       "      <th>WindDirection_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72162.000000</td>\n",
       "      <td>72162.000000</td>\n",
       "      <td>72162.000000</td>\n",
       "      <td>72162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>572.129599</td>\n",
       "      <td>5.696706</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>595.556861</td>\n",
       "      <td>2.619927</td>\n",
       "      <td>0.687171</td>\n",
       "      <td>0.726505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-38.524659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.347222</td>\n",
       "      <td>3.651712</td>\n",
       "      <td>-0.666370</td>\n",
       "      <td>-0.724097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>351.279387</td>\n",
       "      <td>5.330200</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.013277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>961.237629</td>\n",
       "      <td>7.239115</td>\n",
       "      <td>0.683262</td>\n",
       "      <td>0.739171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1779.032433</td>\n",
       "      <td>22.970893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ActivePower     WindSpeed  WindDirection_sin  WindDirection_cos\n",
       "count  72162.000000  72162.000000       72162.000000       72162.000000\n",
       "mean     572.129599      5.696706           0.000225           0.000490\n",
       "std      595.556861      2.619927           0.687171           0.726505\n",
       "min      -38.524659      0.000000          -0.999998          -1.000000\n",
       "25%       51.347222      3.651712          -0.666370          -0.724097\n",
       "50%      351.279387      5.330200          -0.026521          -0.013277\n",
       "75%      961.237629      7.239115           0.683262           0.739171\n",
       "max     1779.032433     22.970893           1.000000           1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/Kaggle Wind Power Forecasting Data/Turbine_Data.csv'\n",
    "df        = pd.read_csv(data_path, parse_dates=[\"Unnamed: 0\"])\n",
    "df        = df[['ActivePower', 'WindDirection','WindSpeed']]\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df['WindDirection_sin'] = np.sin(df['WindDirection'])\n",
    "df['WindDirection_cos'] = np.cos(df['WindDirection'])\n",
    "df.drop('WindDirection', axis=1, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActivePower</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDirection_sin</th>\n",
       "      <th>WindDirection_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>381.634134</td>\n",
       "      <td>4.959830</td>\n",
       "      <td>0.051187</td>\n",
       "      <td>-0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>393.655087</td>\n",
       "      <td>1.723514</td>\n",
       "      <td>0.600078</td>\n",
       "      <td>0.798927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-10.175428</td>\n",
       "      <td>1.306637</td>\n",
       "      <td>-0.999981</td>\n",
       "      <td>-0.999912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.539986</td>\n",
       "      <td>3.558236</td>\n",
       "      <td>-0.387809</td>\n",
       "      <td>-0.871058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>263.965496</td>\n",
       "      <td>4.889602</td>\n",
       "      <td>0.123603</td>\n",
       "      <td>0.044258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>610.756459</td>\n",
       "      <td>6.309334</td>\n",
       "      <td>0.514004</td>\n",
       "      <td>0.857788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1706.169049</td>\n",
       "      <td>9.078578</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ActivePower    WindSpeed  WindDirection_sin  WindDirection_cos\n",
       "count  1000.000000  1000.000000        1000.000000        1000.000000\n",
       "mean    381.634134     4.959830           0.051187          -0.000138\n",
       "std     393.655087     1.723514           0.600078           0.798927\n",
       "min     -10.175428     1.306637          -0.999981          -0.999912\n",
       "25%      53.539986     3.558236          -0.387809          -0.871058\n",
       "50%     263.965496     4.889602           0.123603           0.044258\n",
       "75%     610.756459     6.309334           0.514004           0.857788\n",
       "max    1706.169049     9.078578           0.999998           1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:1000]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 8) (699,)\n",
      "(149, 8) (149,)\n",
      "(151, 8) (151,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "label_column = 'ActivePower'\n",
    "\n",
    "loader = TimeSeriesDataLoader(df, window_size, label_column)\n",
    "X_train, Y_train = loader.get_train_data()\n",
    "X_val  , Y_val   = loader.get_val_data()\n",
    "X_test , Y_test  = loader.get_test_data()\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_val.shape, Y_val.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NESCQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import QuantileRegressionEstimator\n",
    "from Losses import PinballLoss\n",
    "\n",
    "class NESCQR:\n",
    "    def __init__(self, data_loader, model_pool:list, label_pool:list, batch_size:int, M:int, alpha_set:list, \n",
    "                 l_rate:float, max_epochs:int, replace, symmetric, saveflag, save_dir, \n",
    "                 alpha_base=None, step=2, device='cuda', verbose=True):\n",
    "        assert 0 < M <= len(model_pool), \"M must be in range (0, len(model_pool)]\"\n",
    "        self.data_loader = data_loader\n",
    "        self.model_pool  = model_pool\n",
    "        self.label_pool  = label_pool  # 与model_pool里每个模型一一对应的模型名字\n",
    "        self.batch_size  = batch_size\n",
    "        self.M           = M           # 最终的集成模型的基学习器个数\n",
    "        self.alpha_set   = alpha_set   # 置信水平集合\n",
    "        self.l_rate      = l_rate      # 学习率\n",
    "        self.max_epochs  = max_epochs\n",
    "        self.device      = device\n",
    "        self.saveflag   = saveflag\n",
    "        self.save_dir    = save_dir\n",
    "        self.alpha_base  = alpha_base if alpha_base else max(alpha_set)\n",
    "        self.quantiles   = [self.alpha_base / 2, 1 - self.alpha_base / 2]\n",
    "        self.loss_fn     = PinballLoss(self.quantiles, self.device)\n",
    "        self.replace     = replace    # 是否有放回地前向选择\n",
    "        self.step        = step       # DMCQR算法更新步长，int, 越小更新越快越准确\n",
    "        self.symmetric   = symmetric  # 是否采用对称性conformity score\n",
    "        # self.logger      = logger\n",
    "        self.verbose     = verbose\n",
    "        \n",
    "    def init_training(self, saveflag=False):\n",
    "        # 先训练好每个基学习器\n",
    "        X_train, Y_train = self.data_loader.get_train_data(to_tensor=True)\n",
    "        X_val  , Y_val   = self.data_loader.get_val_data(to_tensor=True)\n",
    "        # X_train, Y_train = X_train.to(self.device), Y_train.to(self.device)\n",
    "        # X_val  , Y_val   = X_val.to(self.device), Y_val.to(self.device)\n",
    "\n",
    "        assert len(X_train) == len(Y_train)\n",
    "        assert len(X_val)   == len(Y_val)\n",
    "        \n",
    "        print(f'X_train.shape: {X_train.shape}, Y_train.shape: {Y_train.shape}')\n",
    "        print(f'X_val.shape: {X_val.shape}, Y_val.shape: {Y_val.shape}')\n",
    "        # print(f'X_test.shape: {X_test.shape}, Y_train.shape: {Y_test.shape}')\n",
    "\n",
    "        num_models = len(self.model_pool)\n",
    "        model_pool_trained = []\n",
    "        for i, model in enumerate(self.model_pool):\n",
    "            print(f'Model {i+1}/{num_models} {self.label_pool[i]} starts training...')\n",
    "\n",
    "            # 采用DMCQR得到最终的预测区间，则只需要最大的alpha，即两条分位数即可得到多条预测区间上下界。\n",
    "            learner = QuantileRegressionEstimator(model, [max(self.alpha_set)], self.max_epochs,\n",
    "                                                   self.batch_size,self.device, self.l_rate, self.verbose)\n",
    "            learner.fit(X_train, Y_train, X_val, Y_val)\n",
    "            model_pool_trained.append(learner)\n",
    "            print(f'Model {i+1}/{num_models} {self.label_pool[i]} finished training.')\n",
    "            \n",
    "            if saveflag:\n",
    "                torch.save(learner, f'{self.save_dir}/trained_models/{self.label_pool[i]}.pth')\n",
    "                print(f'Model {i+1}/{num_models} saved.')\n",
    "\n",
    "        return model_pool_trained\n",
    "\n",
    "    def forward_selection(self, model_pool_trained, label_pool, replace=True):\n",
    "        # 前向选择出最优集成模型组合\n",
    "        X_val  , Y_val   = self.data_loader.get_val_data(to_tensor=True)\n",
    "        X_val  , Y_val   = X_val.to(self.device), Y_val.to(self.device)\n",
    "        # pool = dict(zip(label_pool, model_pool_trained))\n",
    "        if replace:\n",
    "            print('Forward selection with replacement.')\n",
    "        else:\n",
    "            print('Forward selection without replacement.')\n",
    "\n",
    "        selected_model, selected_label = [], []\n",
    "        while len(selected_model) < self.M:\n",
    "            best_loss = np.inf\n",
    "            \n",
    "            for i in range(len(model_pool_trained)):\n",
    "                models_ = selected_model + [model_pool_trained[i]]\n",
    "                merged_output = torch.stack([torch.from_numpy(model.predict(X_val)) for model in models_])\n",
    "                merged_output = torch.mean(merged_output, axis=0)\n",
    "                loss = self.loss_fn(merged_output, Y_val)\n",
    "                if loss.item() < best_loss:\n",
    "                    best_model = model_pool_trained[i]\n",
    "                    best_loss  = loss.item()\n",
    "                    best_label = i\n",
    "\n",
    "            selected_model.append(best_model)\n",
    "            selected_label.append(label_pool[best_label])\n",
    "            if not replace:  # 无放回\n",
    "                model_pool_trained.pop(best_label)\n",
    "                label_pool.pop(best_label)\n",
    "                \n",
    "        print(f'Model selected: {selected_label}')\n",
    "\n",
    "        return selected_model, selected_label\n",
    "\n",
    "    def conformal(self, res_val, Y_val, res_test, Y_test, step, symmetric=True):\n",
    "        # DMCQR\n",
    "        assert res_val.shape[0] == Y_val.shape[0]\n",
    "        assert res_val.shape[1] == 2\n",
    "        assert res_test.shape[1] == 2\n",
    "\n",
    "        Y_val  , Y_test   = np.array(Y_val),   np.array(Y_test)\n",
    "        res_val, res_test = np.array(res_val), np.array(res_test)\n",
    "        Y_all     = np.concatenate((Y_val, Y_test), axis=0)\n",
    "        res_all   = np.concatenate((res_val, res_test), axis=0)\n",
    "        num_alpha = len(self.alpha_set)\n",
    "        conf_PI   = np.zeros((len(res_test), num_alpha*2))\n",
    "        val_size  = len(Y_val)\n",
    "        test_size = len(Y_test)\n",
    "\n",
    "        if symmetric:  \n",
    "            # DMCQRS, use symmetric conformity score, 对称误差集合\n",
    "            print('Use symmetric conformity score to calibrate quantiles.')\n",
    "            E = list(np.max((res_val[:, 0] - Y_val, Y_val - res_val[:, -1]), axis=0))  # 误差集合，队列，先进先出\n",
    "            Q = np.zeros(num_alpha)\n",
    "\n",
    "            for t in range(val_size, val_size + test_size):\n",
    "                for i, alpha in enumerate(self.alpha_set):\n",
    "                    Q[i] = np.quantile(E, (1-alpha)*(1+1/val_size))\n",
    "                    conf_PI[:, i] = res_test[:, 0] - Q[i]\n",
    "                    conf_PI[:, -(i+1)] = res_test[:, -1] + Q[i]\n",
    "\n",
    "                    if t % step == 0:\n",
    "                        # print(f't = {t}, Q = {Q}')\n",
    "                        for j in range(t - self.step, t - 1):\n",
    "                            e = np.max((res_all[j, 0] - Y_all[j], Y_all[j] - res_all[j, -1]),axis=0)\n",
    "                            E.pop(0)\n",
    "                            E.append(e)   \n",
    "\n",
    "            return conf_PI\n",
    "        \n",
    "        else:   \n",
    "            # DMCQRS, use asymmetric conformity score, 非对称误差集合\n",
    "            print('Use asymmetric conformity score to calibrate quantiles.')\n",
    "            Q_low, Q_high = np.zeros(num_alpha), np.zeros(num_alpha)\n",
    "            E_low = list(res_val[:, 0] - Y_val)    # 下界误差集合\n",
    "            E_high = list(Y_val - res_val[:,-1])   # 上界误差集合\n",
    "                \n",
    "            for t in range(val_size, val_size + test_size):\n",
    "                for i, alpha in enumerate(self.alpha_set):\n",
    "                    Q_low[i] = np.quantile(E_low, (1 - alpha / 2))\n",
    "                    Q_high[-(i+1)] = np.quantile(E_high, (1 - alpha / 2))\n",
    "                    \n",
    "                    conf_PI[:, i] = res_test[:, 0] - Q_low[i]\n",
    "                    conf_PI[:, -(i+1)] = res_test[:, -1] + Q_high[-(i+1)]\n",
    "\n",
    "                if t % step == 0:\n",
    "                    # print(f't: {t}, Q_low: {Q_low}, Q_high: {Q_high}')\n",
    "                    for j in range(t - step, t - 1):\n",
    "                        e_low = res_all[j, 0] - Y_all[j]\n",
    "                        e_high = Y_all[j] - res_all[j, -1]\n",
    "                        E_low.pop(0)\n",
    "                        E_low.append(e_low)\n",
    "                        E_high.pop(0)\n",
    "                        E_high.append(e_high)\n",
    "\n",
    "            return conf_PI     \n",
    "\n",
    "    def fit(self):\n",
    "        self.model_pool_trained = self.init_training()\n",
    "        self.model_pool_selected, self.selected_label = self.forward_selection(self.model_pool_trained, self.label_pool, self.replace)\n",
    "\n",
    "    def predict(self, X_test=None, Y_test=None, inverse_normalization=True):\n",
    "        # construct prediction intervals\n",
    "        X_val  , Y_val   = self.data_loader.get_val_data(to_tensor=True)\n",
    "        if not X_test:\n",
    "            X_test,  Y_test  = self.data_loader.get_test_data(to_tensor=True)\n",
    "        Y_val  , Y_test  = Y_val.detach().numpy(), Y_test.detach().numpy()\n",
    "        X_val   = X_val.to(self.device)\n",
    "        X_test  = X_test.to(self.device)\n",
    "\n",
    "        # pred = self.model_pool_selected[0].predict(X_val)\n",
    "        # print(f'pred.shape: {pred.shape}')\n",
    "        res_val = torch.stack([torch.from_numpy(model.predict(X_val)) for model in self.model_pool_selected])\n",
    "        res_val = torch.mean(res_val, axis=0)\n",
    "        res_val = res_val.detach().numpy()\n",
    "        res_test = torch.stack([torch.from_numpy(model.predict(X_test)) for model in self.model_pool_selected])\n",
    "        res_test = torch.mean(res_test, axis=0)\n",
    "        res_test = res_test.detach().numpy()\n",
    "        # print(f'res_val.shape: {res_val.shape}, res_test.shape: {res_test.shape}')\n",
    "\n",
    "        self.conf_PI = self.conformal(res_val, Y_val, res_test, Y_test, self.step, self.symmetric)\n",
    "        if inverse_normalization:  # 逆标准化回原来的量纲\n",
    "            self.conf_PI = self.data_loader.inverse_transform(self.conf_PI, is_label=True)\n",
    "\n",
    "        cols = [str(round(alpha/2, 3)) for alpha in self.alpha_set] + [str(round(1-alpha/2, 3)) for alpha in reversed(self.alpha_set)]\n",
    "        if self.saveflag:\n",
    "            df = pd.DataFrame(self.conf_PI, columns=cols)\n",
    "            df.to_csv(os.path.join(self.save_dir,'conf_PIs.csv'), index=False)\n",
    "            \n",
    "        return self.conf_PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\\2023_10_09_17_25_14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Postgraduate\\papers\\NESCQR\\code\\NESCQR\\venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BPNN_20', 'RNN_20', 'LSTM_20', 'GRU_20', 'TCN_3']\n"
     ]
    }
   ],
   "source": [
    "# 获取当前时间戳\n",
    "current_time = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "# 构建文件夹路径\n",
    "save_dir = os.path.join(\"result\", current_time)\n",
    "print(save_dir)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "n_ensemble = 3  #number of baseline models, which is M in paper.\n",
    "M          = n_ensemble\n",
    "max_epochs = 100\n",
    "l_rate     = 1e-4\n",
    "activation = 'tanh'  #nn.Tanh,              nn.ReLU, nn.Sigmoid\n",
    "batch_size = 512\n",
    "dropout    = 0.2\n",
    "replace    = False\n",
    "symmetric  = True\n",
    "saveflag   = True\n",
    "# save_dir   = './results/'\n",
    "step       = 2\n",
    "device     = 'cuda'\n",
    "verbose    = True\n",
    "\n",
    "alpha_set = np.array([0.05, 0.10, 0.15])\n",
    "num_alpha = len(alpha_set)\n",
    "alpha_base = max(alpha_set)\n",
    "quantiles = [max(alpha_set)/2, 1 - max(alpha_set)/2]\n",
    "# quantiles = np.zeros(2*num_alpha)\n",
    "# for i in range(num_alpha):\n",
    "#     quantiles[i] = alpha_set[i] / 2\n",
    "#     quantiles[-(i+1)] = 1 - alpha_set[i] / 2\n",
    "\n",
    "# loss_fn = PinballLoss(quantiles=quantiles, device=device)\n",
    "input_dim = X_train.shape[1]\n",
    "x_size = len(df.columns)\n",
    "out_dim = len(quantiles)\n",
    "kernel_size = 2\n",
    "num_repeat = 1\n",
    "hidden_units = [20 + i*4 for i in range(num_repeat)]\n",
    "channel_sizes = [3 + i*2 for i in range(num_repeat)]\n",
    "\n",
    "model_pool = [NET(input_dim, h, out_dim, activation) for h in hidden_units] + \\\n",
    "             [RNN(input_dim, h, out_dim, activation, device) for h in hidden_units] + \\\n",
    "             [LSTM(input_dim, h, out_dim, device) for h in hidden_units] + \\\n",
    "             [GRU(x_size, h, out_dim, device) for h in hidden_units] + \\\n",
    "             [TCN(x_size, out_dim, [c]*2, kernel_size, dropout) for c in channel_sizes]\n",
    "             \n",
    "# label_pool = ['BPNN']*num_repeat + ['RNN']*num_repeat + ['LSTM']*num_repeat + ['GRU']*num_repeat + ['TCN']*num_repeat\n",
    "label_pool = [f'BPNN_{h}' for h in hidden_units] + \\\n",
    "             [f'RNN_{h}' for h in hidden_units] + \\\n",
    "             [f'LSTM_{h}' for h in hidden_units] + \\\n",
    "             [f'GRU_{h}' for h in hidden_units] + \\\n",
    "             [f'TCN_{c}' for c in channel_sizes]\n",
    "\n",
    "nescqr = NESCQR(loader, model_pool, label_pool, batch_size, M, alpha_set, \n",
    "                 l_rate, max_epochs, replace, symmetric, saveflag, save_dir, alpha_base, step, \n",
    "                  device, verbose)\n",
    "\n",
    "print(label_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: torch.Size([699, 8]), Y_train.shape: torch.Size([699])\n",
      "X_val.shape: torch.Size([149, 8]), Y_val.shape: torch.Size([149])\n",
      "Model 1/5 BPNN_20 starts training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100, train_loss: 0.4576, validation_loss: 0.4776, cost_time: 0.01s\n",
      "Model 1/5 BPNN_20 finished training.\n",
      "Model 2/5 RNN_20 starts training...\n",
      "Epoch:100, train_loss: 0.3846, validation_loss: 0.4155, cost_time: 0.04s\n",
      "Model 2/5 RNN_20 finished training.\n",
      "Model 3/5 LSTM_20 starts training...\n",
      "Epoch:100, train_loss: 0.3405, validation_loss: 0.3773, cost_time: 0.02s\n",
      "Model 3/5 LSTM_20 finished training.\n",
      "Model 4/5 GRU_20 starts training...\n",
      "Epoch:100, train_loss: 0.2980, validation_loss: 0.3158, cost_time: 0.02s\n",
      "Model 4/5 GRU_20 finished training.\n",
      "Model 5/5 TCN_3 starts training...\n",
      "Epoch:100, train_loss: 0.4268, validation_loss: 0.4737, cost_time: 0.03s\n",
      "Model 5/5 TCN_3 finished training.\n",
      "Forward selection without replacement.\n",
      "Model selected: ['GRU_20', 'LSTM_20', 'RNN_20']\n",
      "Use symmetric conformity score to calibrate quantiles.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(151, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test , Y_test  = loader.get_test_data(to_tensor=True)\n",
    "nescqr.fit()\n",
    "conf_PI = nescqr.predict()\n",
    "conf_PI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-114.16654582,   -7.01886777,   35.60748987,  828.22364489,\n",
       "        870.84997908,  977.99765713])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_PI[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINC: 95%, MAE: 240.6084, MSE: 82685.2742, RMSE: 287.5505, CRPS: 240.6084, SDE: 287.5429\n",
      "PINC: 95%, PICP: 96.0265, MPIW: 1142.8249, PINAW: 0.8819, F: 0.0018, ACE: 1.0265, CWC: 0.8819,                   interval_score: 1351.6154\n",
      "PINC: 90%, MAE: 240.6084, MSE: 82685.2741, RMSE: 287.5505, CRPS: 240.6084, SDE: 287.5429\n",
      "PINC: 90%, PICP: 92.7152, MPIW: 928.5296, PINAW: 0.7165, F: 0.0022, ACE: 2.7152, CWC: 0.7165,                   interval_score: 1145.3501\n",
      "PINC: 85%, MAE: 240.6084, MSE: 82685.2738, RMSE: 287.5505, CRPS: 240.6084, SDE: 287.5429\n",
      "PINC: 85%, PICP: 88.7417, MPIW: 843.2769, PINAW: 0.6507, F: 0.0024, ACE: 3.7417, CWC: 0.6507,                   interval_score: 1038.7122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINC</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>CRPS</th>\n",
       "      <th>SDE</th>\n",
       "      <th>PICP</th>\n",
       "      <th>MPIW</th>\n",
       "      <th>F</th>\n",
       "      <th>PINAW</th>\n",
       "      <th>ACE</th>\n",
       "      <th>CWC</th>\n",
       "      <th>Interval score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.0</td>\n",
       "      <td>240.608406</td>\n",
       "      <td>82685.274228</td>\n",
       "      <td>287.550472</td>\n",
       "      <td>240.608406</td>\n",
       "      <td>287.542934</td>\n",
       "      <td>96.026490</td>\n",
       "      <td>1142.824948</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.881895</td>\n",
       "      <td>1.026490</td>\n",
       "      <td>0.881895</td>\n",
       "      <td>1351.615429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.0</td>\n",
       "      <td>240.608406</td>\n",
       "      <td>82685.274135</td>\n",
       "      <td>287.550472</td>\n",
       "      <td>240.608406</td>\n",
       "      <td>287.542934</td>\n",
       "      <td>92.715232</td>\n",
       "      <td>928.529592</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.716528</td>\n",
       "      <td>2.715232</td>\n",
       "      <td>0.716528</td>\n",
       "      <td>1145.350070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.0</td>\n",
       "      <td>240.608405</td>\n",
       "      <td>82685.273756</td>\n",
       "      <td>287.550472</td>\n",
       "      <td>240.608405</td>\n",
       "      <td>287.542933</td>\n",
       "      <td>88.741722</td>\n",
       "      <td>843.276878</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>0.650740</td>\n",
       "      <td>3.741722</td>\n",
       "      <td>0.650740</td>\n",
       "      <td>1038.712174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PINC         MAE           MSE        RMSE        CRPS         SDE  \\\n",
       "0  95.0  240.608406  82685.274228  287.550472  240.608406  287.542934   \n",
       "1  90.0  240.608406  82685.274135  287.550472  240.608406  287.542934   \n",
       "2  85.0  240.608405  82685.273756  287.550472  240.608405  287.542933   \n",
       "\n",
       "        PICP         MPIW         F     PINAW       ACE       CWC  \\\n",
       "0  96.026490  1142.824948  0.001750  0.881895  1.026490  0.881895   \n",
       "1  92.715232   928.529592  0.002154  0.716528  2.715232  0.716528   \n",
       "2  88.741722   843.276878  0.002372  0.650740  3.741722  0.650740   \n",
       "\n",
       "   Interval score  \n",
       "0     1351.615429  \n",
       "1     1145.350070  \n",
       "2     1038.712174  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_original = loader.inverse_transform(Y_test)\n",
    "res = evaluate(Y_test_original, conf_PI, alpha_set)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cross-bound phenomenon.\n",
      "MUCW = 0.0000, MLCW = 0.0000\n",
      "Cross loss:  0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUCW</th>\n",
       "      <th>MLCW</th>\n",
       "      <th>Cross loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MUCW  MLCW  Cross loss\n",
       "0     0     0         0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cross = cross_bound_check(conf_PI)\n",
    "res_cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnbPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: torch.Size([699, 8]), Y_train.shape: torch.Size([699])\n",
      "X_val.shape: torch.Size([149, 8]), Y_val.shape: torch.Size([149])\n",
      "X_test.shape: torch.Size([151, 8]), Y_train.shape: torch.Size([151])\n",
      "X_train_enpi.shape: torch.Size([848, 8]), Y_train_enpi.shape: torch.Size([848])\n",
      "-- EnbPI training: 1 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([848, 8]), y_s_b = torch.Size([848, 1]), x_no_s_b.shape = torch.Size([316, 8]), y_no_s_b.shape = torch.Size([316, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Postgraduate\\papers\\NESCQR\\code\\NESCQR\\venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100, train_loss: 0.7713, validation_loss: 0.7009, cost_time: 0.01s\n",
      "model: 1 finished training.\n",
      "-- EnbPI training: 2 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([848, 8]), y_s_b = torch.Size([848, 1]), x_no_s_b.shape = torch.Size([314, 8]), y_no_s_b.shape = torch.Size([314, 1])\n",
      "Epoch:100, train_loss: 0.7941, validation_loss: 0.6637, cost_time: 0.04s\n",
      "model: 2 finished training.\n",
      "-- EnbPI training: 3 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([848, 8]), y_s_b = torch.Size([848, 1]), x_no_s_b.shape = torch.Size([315, 8]), y_no_s_b.shape = torch.Size([315, 1])\n",
      "Epoch:100, train_loss: 1.0312, validation_loss: 1.1236, cost_time: 0.02s\n",
      "model: 3 finished training.\n",
      "-- EnbPI training: 4 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([848, 8]), y_s_b = torch.Size([848, 1]), x_no_s_b.shape = torch.Size([304, 8]), y_no_s_b.shape = torch.Size([304, 1])\n",
      "Epoch:100, train_loss: 0.7803, validation_loss: 0.6014, cost_time: 0.02s\n",
      "model: 4 finished training.\n",
      "-- EnbPI training: 5 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([848, 8]), y_s_b = torch.Size([848, 1]), x_no_s_b.shape = torch.Size([312, 8]), y_no_s_b.shape = torch.Size([312, 1])\n",
      "Epoch:100, train_loss: 1.2393, validation_loss: 1.2177, cost_time: 0.02s\n",
      "model: 5 finished training.\n"
     ]
    }
   ],
   "source": [
    "from algorithms import EnbPI\n",
    "\n",
    "X_train, Y_train = loader.get_train_data(to_tensor=True)\n",
    "X_val  , Y_val   = loader.get_val_data(to_tensor=True)\n",
    "X_test , Y_test  = loader.get_test_data(to_tensor=True)\n",
    "print(f'X_train.shape: {X_train.shape}, Y_train.shape: {Y_train.shape}')\n",
    "print(f'X_val.shape: {X_val.shape}, Y_val.shape: {Y_val.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}, Y_train.shape: {Y_test.shape}')\n",
    "\n",
    "X_train_enpi = torch.cat((X_train, X_val), axis=0)\n",
    "Y_train_enpi = torch.cat((Y_train, Y_val), axis=0)\n",
    "print(f'X_train_enpi.shape: {X_train_enpi.shape}, Y_train_enpi.shape: {Y_train_enpi.shape}')\n",
    "\n",
    "# Define models\n",
    "model_pool_enbpi = [NET(input_dim, h, 1, activation) for h in hidden_units] + \\\n",
    "             [RNN(input_dim, h, 1, activation, device) for h in hidden_units] + \\\n",
    "             [LSTM(input_dim, h, 1, device) for h in hidden_units] + \\\n",
    "             [GRU(x_size, h, 1, device) for h in hidden_units] + \\\n",
    "             [TCN(x_size, 1, [c]*2, kernel_size, dropout) for c in channel_sizes]\n",
    "\n",
    "enbpi = EnbPI(model_pool_enbpi, alpha_set, l_rate, max_epochs, batch_size, device, verbose)\n",
    "enbpi.fit(X_train_enpi, Y_train_enpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf_PI_enbpi.shape: (151, 6)\n",
      "PINC: 95%, MAE: 232.4761, MSE: 80074.1937, RMSE: 282.9738, CRPS: 232.4761, SDE: 265.6705\n",
      "PINC: 95%, PICP: 98.6755, MPIW: 1621.1110, PINAW: 1.2510, F: 0.0012, ACE: 3.6755, CWC: 1.2510,                   interval_score: 1641.4330\n",
      "PINC: 90%, MAE: 232.4761, MSE: 80074.1937, RMSE: 282.9738, CRPS: 232.4761, SDE: 265.6705\n",
      "PINC: 90%, PICP: 96.6887, MPIW: 1157.1120, PINAW: 0.8929, F: 0.0017, ACE: 6.6887, CWC: 0.8929,                   interval_score: 1279.8153\n",
      "PINC: 85%, MAE: 232.4761, MSE: 80074.1937, RMSE: 282.9738, CRPS: 232.4761, SDE: 265.6705\n",
      "PINC: 85%, PICP: 91.3907, MPIW: 910.4007, PINAW: 0.7025, F: 0.0022, ACE: 6.3907, CWC: 0.7025,                   interval_score: 1082.8327\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINC</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>CRPS</th>\n",
       "      <th>SDE</th>\n",
       "      <th>PICP</th>\n",
       "      <th>MPIW</th>\n",
       "      <th>F</th>\n",
       "      <th>PINAW</th>\n",
       "      <th>ACE</th>\n",
       "      <th>CWC</th>\n",
       "      <th>Interval score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.0</td>\n",
       "      <td>232.476114</td>\n",
       "      <td>80074.193705</td>\n",
       "      <td>282.973839</td>\n",
       "      <td>232.476114</td>\n",
       "      <td>265.670533</td>\n",
       "      <td>98.675497</td>\n",
       "      <td>1621.111024</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>1.250979</td>\n",
       "      <td>3.675497</td>\n",
       "      <td>1.250979</td>\n",
       "      <td>1641.433042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.0</td>\n",
       "      <td>232.476114</td>\n",
       "      <td>80074.193705</td>\n",
       "      <td>282.973839</td>\n",
       "      <td>232.476114</td>\n",
       "      <td>265.670533</td>\n",
       "      <td>96.688742</td>\n",
       "      <td>1157.111970</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.892920</td>\n",
       "      <td>6.688742</td>\n",
       "      <td>0.892920</td>\n",
       "      <td>1279.815275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.0</td>\n",
       "      <td>232.476114</td>\n",
       "      <td>80074.193705</td>\n",
       "      <td>282.973839</td>\n",
       "      <td>232.476114</td>\n",
       "      <td>265.670533</td>\n",
       "      <td>91.390728</td>\n",
       "      <td>910.400674</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.702538</td>\n",
       "      <td>6.390728</td>\n",
       "      <td>0.702538</td>\n",
       "      <td>1082.832688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PINC         MAE           MSE        RMSE        CRPS         SDE  \\\n",
       "0  95.0  232.476114  80074.193705  282.973839  232.476114  265.670533   \n",
       "1  90.0  232.476114  80074.193705  282.973839  232.476114  265.670533   \n",
       "2  85.0  232.476114  80074.193705  282.973839  232.476114  265.670533   \n",
       "\n",
       "        PICP         MPIW         F     PINAW       ACE       CWC  \\\n",
       "0  98.675497  1621.111024  0.001234  1.250979  3.675497  1.250979   \n",
       "1  96.688742  1157.111970  0.001728  0.892920  6.688742  0.892920   \n",
       "2  91.390728   910.400674  0.002197  0.702538  6.390728  0.702538   \n",
       "\n",
       "   Interval score  \n",
       "0     1641.433042  \n",
       "1     1279.815275  \n",
       "2     1082.832688  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_PI_enbpi = enbpi.predict_interval(X_train_enpi, Y_train_enpi, X_test, Y_test, step)\n",
    "conf_PI_enbpi = loader.inverse_transform(conf_PI_enbpi, is_label=True)\n",
    "print(f'conf_PI_enbpi.shape: {conf_PI_enbpi.shape}')\n",
    "\n",
    "res_enbpi = evaluate(Y_test_original, conf_PI_enbpi, alpha_set)\n",
    "res_enbpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cross-bound phenomenon.\n",
      "MUCW = 0.0000, MLCW = 0.0000\n",
      "Cross loss:  0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUCW</th>\n",
       "      <th>MLCW</th>\n",
       "      <th>Cross loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MUCW  MLCW  Cross loss\n",
       "0     0     0         0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_bound_check(conf_PI_enbpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnCQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EnCQR(train_data, val_x, val_y, test_x, test_y, P):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data : list of data to train an ensemble of models\n",
    "    test_x : input test data\n",
    "    test_y : output test data\n",
    "    P : dictionary of parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PI : original PI produced by the ensemble model\n",
    "    conf_PI : PI after the conformalization\n",
    "    \"\"\"\n",
    "\n",
    "    index = np.arange(P['B'])\n",
    "    s = P['time_steps_out']\n",
    "    \n",
    "    # dict containing LOO predictions\n",
    "    dct_lo = {}\n",
    "    dct_hi = {}\n",
    "    for key in index:\n",
    "      dct_lo['pred_%s' % key] = []\n",
    "      dct_hi['pred_%s' % key] = []\n",
    "    \n",
    "    # training a model for each sub set Sb\n",
    "    ensemble_models = []\n",
    "    for b in range(P['B']):\n",
    "        f_hat_b = regression_model(P)\n",
    "        f_hat_b.fit(train_data[index[b]][0], train_data[index[b]][1], val_x, val_y)\n",
    "        ensemble_models.append(f_hat_b)\n",
    "        \n",
    "        # Leave-one-out predictions for each Sb\n",
    "        indx_LOO = index[np.arange(len(index))!=b]\n",
    "        for i in range(len(indx_LOO)):\n",
    "            pred = f_hat_b.transform(train_data[indx_LOO[i]][0])\n",
    "            dct_lo['pred_%s' %indx_LOO[i]].append(pred[:,:,0])\n",
    "            dct_hi['pred_%s' %indx_LOO[i]].append(pred[:,:,2])\n",
    "            \n",
    "    f_hat_b_agg_low  = np.zeros((train_data[index[0]][0].shape[0], P['time_steps_out'], P['B']))\n",
    "    f_hat_b_agg_high = np.zeros((train_data[index[0]][0].shape[0], P['time_steps_out'], P['B']))\n",
    "    for b in range(P['B']):\n",
    "        f_hat_b_agg_low[:,:,b] = np.mean(dct_lo['pred_%s' %b],axis=0) \n",
    "        f_hat_b_agg_high[:,:,b] = np.mean(dct_hi['pred_%s' %b],axis=0)  \n",
    "        \n",
    "    # residuals on the training data\n",
    "    epsilon_low = []\n",
    "    epsilon_hi=[]\n",
    "    for b in range(P['B']):\n",
    "        e_low, e_high = utils.asym_nonconformity(label=train_data[b][1], \n",
    "                                                  low=f_hat_b_agg_low[:,:,b], \n",
    "                                                  high=f_hat_b_agg_high[:,:,b])\n",
    "        epsilon_low.append(e_low)\n",
    "        epsilon_hi.append(e_high)\n",
    "    epsilon_low = np.array(epsilon_low).flatten()\n",
    "    epsilon_hi = np.array(epsilon_hi).flatten()\n",
    "            \n",
    "    # Construct PIs for test data\n",
    "    f_hat_t_batch = np.zeros((test_y.shape[0], test_y.shape[1], 3, P['B']))\n",
    "    for b, model_b in enumerate(ensemble_models):\n",
    "        f_hat_t_batch[:,:,:,b] = model_b.transform(test_x)\n",
    "    PI  = np.mean(f_hat_t_batch,  axis=-1) \n",
    "    \n",
    "    # Conformalize prediction intervals on the test data\n",
    "    conf_PI = np.zeros((test_y.shape[0], test_y.shape[1], 3))\n",
    "    conf_PI[:,:,1] = PI[:,:,1]\n",
    "    for i in range(test_y.shape[0]):   \n",
    "        e_quantile_lo = np.quantile(epsilon_low, 1-P['alpha']/2)\n",
    "        e_quantile_hi = np.quantile(epsilon_hi, 1-P['alpha']/2)\n",
    "        conf_PI[i,:,0] = PI[i,:,0] - e_quantile_lo\n",
    "        conf_PI[i,:,2] = PI[i,:,2] + e_quantile_hi\n",
    "    \n",
    "        # update epsilon with the last s steps\n",
    "        e_lo, e_hi = utils.asym_nonconformity(label=test_y[i,:],\n",
    "                                                low=PI[i,:,0],\n",
    "                                                high=PI[i,:,2])\n",
    "        epsilon_low = np.delete(epsilon_low,slice(0,s,1))\n",
    "        epsilon_hi = np.delete(epsilon_hi,slice(0,s,1))\n",
    "        epsilon_low = np.append(epsilon_low, e_lo)\n",
    "        epsilon_hi = np.append(epsilon_hi, e_hi)\n",
    "        \n",
    "    return PI, conf_PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnCQR():\n",
    "    def __init__(self, model_pool, alpha_set, l_rate:float, max_epochs:int, batch_size:int, device='cuda', verbose=True):\n",
    "\n",
    "        self.n_ensemble = len(model_pool)  #基学习器数量\n",
    "        self.NNs = model_pool\n",
    "        self.l_rate = l_rate  #学习率\n",
    "        self.max_epochs = max_epochs\n",
    "        self.batch_size = batch_size  #越大更新越慢，int.\n",
    "        self.device = device\n",
    "        self.verbose = verbose  #是否输出中间过程\n",
    "        self.alpha_set = alpha_set\n",
    "        self.num_alpha = len(alpha_set)\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "    \n",
    "        T = X_train.shape[0]\n",
    "        tb = int(np.floor(T / self.n_ensemble))\n",
    "\n",
    "        S = np.arange(0, T)\n",
    "        for b in range(self.n_ensemble):\n",
    "            print('-- EnCQR training: ' + str(b+1) + ' of ' + str(self.n_ensemble) + ' NNs --')\n",
    "\n",
    "            s_b = range(tb*b, (tb*b+tb))\n",
    "            no_s_b = np.delete(S, s_b, 0)\n",
    "            x_s_b, y_s_b = X_train[s_b, :], Y_train[s_b].reshape(len(s_b), 1)\n",
    "\n",
    "            x_no_s_b = X_train[no_s_b, :]\n",
    "            y_no_s_b = Y_train[no_s_b].reshape(len(no_s_b), 1)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f'x_s_b.shape = {x_s_b.shape}, y_s_b = {y_s_b.shape}, x_no_s_b.shape = {x_no_s_b.shape}, y_no_s_b.shape = {y_no_s_b.shape}')\n",
    "\n",
    "            learner = QuantileRegressionEstimator(self.NNs[b], self.alpha_set, self.max_epochs, self.batch_size, self.device, self.l_rate, self.verbose)\n",
    "            learner.fit(x_s_b, y_s_b, x_no_s_b, y_no_s_b)\n",
    "            print('Model: %d finished training.' % (b+1))  \n",
    "        \n",
    "        self.no_s_b = no_s_b\n",
    "\n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        分位数预测。Quantile regression.\n",
    "\n",
    "        out:\n",
    "        res: point forecasting results of x, ndarray, [N, ].\n",
    "        '''\n",
    "        n_ensemble = len(self.NNs)\n",
    "        P = torch.zeros(n_ensemble, x.shape[0], self.num_alpha*2)\n",
    "\n",
    "        for b in range(n_ensemble):\n",
    "\n",
    "            model = self.NNs[b]\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x = x.to(self.device)\n",
    "                pred = model(x)\n",
    "            \n",
    "            P[b, :, :] = pred.to(torch.float32)\n",
    "        \n",
    "        res = P.mean(axis=0)\n",
    "        res = res.numpy()\n",
    "        res = res.squeeze()\n",
    "\n",
    "        return res\n",
    "\n",
    "    def predict_interval(self, X_train, Y_train, X_test, Y_test, step=None):\n",
    "        '''\n",
    "        区间预测。Interval prediction. fit完直接就可以调用来构造预测区间。\n",
    "        \n",
    "        out:\n",
    "        C: prediction intervals.\n",
    "        '''\n",
    "        \n",
    "        Y_train, Y_test = np.array(Y_train), np.array(Y_test)\n",
    "\n",
    "        res_train = self.predict(X_train)\n",
    "        res_test = self.predict(X_test)\n",
    "        T1 = res_test.shape[0]\n",
    "        if step == None:\n",
    "            step = self.batch_size\n",
    "\n",
    "        # Initialize the asymmetric conformity scores.\n",
    "        C = np.zeros((T1, self.num_alpha*2))\n",
    "        E_low, E_high = np.zeros((len(self.no_s_b), self.num_alpha)), np.zeros((len(self.no_s_b), self.num_alpha))\n",
    "        Q_low, Q_high = np.zeros((self.num_alpha,)), np.zeros((self.num_alpha,))\n",
    "        for i in range(self.num_alpha):\n",
    "            E_low[:, i] = (res_train[self.no_s_b, i].reshape((len(self.no_s_b),1)) - Y_train[self.no_s_b].reshape((len(self.no_s_b),1))).squeeze()\n",
    "            E_high[:, -(i+1)] = (Y_train[self.no_s_b].reshape((len(self.no_s_b),1)) - res_train[self.no_s_b, -(i+1)].reshape((len(self.no_s_b),1))).squeeze()\n",
    "\n",
    "        # Comformalize the prediction intervals.\n",
    "        for t in range(T1):\n",
    "            for i, alpha in enumerate(self.alpha_set):\n",
    "                \n",
    "                Q_low[i] = np.quantile(E_low[:, i], 1 - alpha / 2)\n",
    "                Q_high[-(i+1)] = np.quantile(E_high[:, -(i+1)], 1 - alpha / 2)\n",
    "\n",
    "                C[t, i] = res_test[t, i] - Q_low[i]\n",
    "                C[t, -(i+1)] = res_test[t, -(i+1)] + Q_high[-(i+1)]\n",
    "\n",
    "            # Update the lists of conformity scores\n",
    "            if t % step == 0 and step < T1:\n",
    "                # print('t = %d, Q_low[0] = %f, Q_high[-1] = %f, E_low.shape = %s, E_high.shape = %s.' % \n",
    "                #   (t,Q_low[0],Q_high[-1],str(E_low.shape), str(E_high.shape)))\n",
    "                for j in range(t - step, t-1):\n",
    "                    for i in range(self.num_alpha):\n",
    "                        e_low = res_test[j, i] - Y_test[j]\n",
    "                        e_high = Y_test[j] - res_test[j, -(i+1)]\n",
    "                        E_low_temp = np.delete(E_low[:,i], 0, 0)    #删除第一个元素\n",
    "                        E_low_temp = np.append(E_low_temp, e_low)   #添加新的元素\n",
    "                        E_low[:,i] = E_low_temp\n",
    "                        E_high_temp = np.delete(E_high[:,-(i+1)], 0, 0)\n",
    "                        E_high_temp = np.append(E_high_temp, e_high)\n",
    "                        E_high[:,-(i+1)] = E_high_temp   \n",
    "\n",
    "        return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Postgraduate\\papers\\NESCQR\\code\\NESCQR\\venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- EnCQR training: 1 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([169, 8]), y_s_b = torch.Size([169, 1]), x_no_s_b.shape = torch.Size([679, 8]), y_no_s_b.shape = torch.Size([679, 1])\n",
      "Epoch:100, train_loss: 0.4210, validation_loss: 0.4740, cost_time: 0.01s\n",
      "Model: 1 finished training.\n",
      "-- EnCQR training: 2 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([169, 8]), y_s_b = torch.Size([169, 1]), x_no_s_b.shape = torch.Size([679, 8]), y_no_s_b.shape = torch.Size([679, 1])\n",
      "Epoch:100, train_loss: 0.4419, validation_loss: 0.5248, cost_time: 0.01s\n",
      "Model: 2 finished training.\n",
      "-- EnCQR training: 3 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([169, 8]), y_s_b = torch.Size([169, 1]), x_no_s_b.shape = torch.Size([679, 8]), y_no_s_b.shape = torch.Size([679, 1])\n",
      "Epoch:100, train_loss: 0.4299, validation_loss: 0.4618, cost_time: 0.01s\n",
      "Model: 3 finished training.\n",
      "-- EnCQR training: 4 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([169, 8]), y_s_b = torch.Size([169, 1]), x_no_s_b.shape = torch.Size([679, 8]), y_no_s_b.shape = torch.Size([679, 1])\n",
      "Epoch:100, train_loss: 0.3632, validation_loss: 0.4889, cost_time: 0.01s\n",
      "Model: 4 finished training.\n",
      "-- EnCQR training: 5 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([169, 8]), y_s_b = torch.Size([169, 1]), x_no_s_b.shape = torch.Size([679, 8]), y_no_s_b.shape = torch.Size([679, 1])\n",
      "Epoch:100, train_loss: 0.4862, validation_loss: 0.3615, cost_time: 0.01s\n",
      "Model: 5 finished training.\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "out_dim_encqr = len(alpha_set) * 2\n",
    "model_pool_encqr = [NET(input_dim, h, out_dim_encqr, activation) for h in hidden_units] + \\\n",
    "             [RNN(input_dim, h, out_dim_encqr, activation, device) for h in hidden_units] + \\\n",
    "             [LSTM(input_dim, h, out_dim_encqr, device) for h in hidden_units] + \\\n",
    "             [GRU(x_size, h, out_dim_encqr, device) for h in hidden_units] + \\\n",
    "             [TCN(x_size, out_dim_encqr, [c]*2, kernel_size, dropout) for c in channel_sizes]\n",
    "\n",
    "encqr = EnCQR(model_pool_encqr, alpha_set, l_rate, max_epochs, batch_size, device)\n",
    "encqr.fit(X_train_enpi, Y_train_enpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 845 is out of bounds for axis 0 with size 699",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\Postgraduate\\papers\\NESCQR\\code\\NESCQR\\notebook\\Wind Power Forecasting Demo.ipynb 单元格 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Postgraduate/papers/NESCQR/code/NESCQR/notebook/Wind%20Power%20Forecasting%20Demo.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m conf_PI_encqr \u001b[39m=\u001b[39m encqr\u001b[39m.\u001b[39;49mpredict_interval(X_train, Y_train, X_test, Y_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Postgraduate/papers/NESCQR/code/NESCQR/notebook/Wind%20Power%20Forecasting%20Demo.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconf_PI_encqr.shape: \u001b[39m\u001b[39m{\u001b[39;00mconf_PI_encqr\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Postgraduate/papers/NESCQR/code/NESCQR/notebook/Wind%20Power%20Forecasting%20Demo.ipynb#X35sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m conf_PI_encqr \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39minverse_transform(conf_PI_encqr, is_label\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mf:\\Postgraduate\\papers\\NESCQR\\code\\NESCQR\\notebook\\Wind Power Forecasting Demo.ipynb 单元格 22\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Postgraduate/papers/NESCQR/code/NESCQR/notebook/Wind%20Power%20Forecasting%20Demo.ipynb#X35sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m Q_low, Q_high \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_alpha,)), np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_alpha,))\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Postgraduate/papers/NESCQR/code/NESCQR/notebook/Wind%20Power%20Forecasting%20Demo.ipynb#X35sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_alpha):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Postgraduate/papers/NESCQR/code/NESCQR/notebook/Wind%20Power%20Forecasting%20Demo.ipynb#X35sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m     E_low[:, i] \u001b[39m=\u001b[39m (res_train[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mno_s_b, i]\u001b[39m.\u001b[39mreshape((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_s_b),\u001b[39m1\u001b[39m)) \u001b[39m-\u001b[39m Y_train[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_s_b]\u001b[39m.\u001b[39mreshape((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_s_b),\u001b[39m1\u001b[39m)))\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Postgraduate/papers/NESCQR/code/NESCQR/notebook/Wind%20Power%20Forecasting%20Demo.ipynb#X35sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     E_high[:, \u001b[39m-\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)] \u001b[39m=\u001b[39m (Y_train[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_s_b]\u001b[39m.\u001b[39mreshape((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_s_b),\u001b[39m1\u001b[39m)) \u001b[39m-\u001b[39m res_train[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_s_b, \u001b[39m-\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)]\u001b[39m.\u001b[39mreshape((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_s_b),\u001b[39m1\u001b[39m)))\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Postgraduate/papers/NESCQR/code/NESCQR/notebook/Wind%20Power%20Forecasting%20Demo.ipynb#X35sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39m# Comformalize the prediction intervals.\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 845 is out of bounds for axis 0 with size 699"
     ]
    }
   ],
   "source": [
    "conf_PI_encqr = encqr.predict_interval(X_train, Y_train, X_test, Y_test)\n",
    "print(f'conf_PI_encqr.shape: {conf_PI_encqr.shape}')\n",
    "\n",
    "conf_PI_encqr = loader.inverse_transform(conf_PI_encqr, is_label=True)\n",
    "\n",
    "res_encqr = evaluate(Y_test_original, conf_PI_encqr, alpha_set)\n",
    "res_encqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
       "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
       "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
       "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
       "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
       "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
       "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
       "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
       "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
       "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
       "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
       "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
       "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
       "       845, 846, 847])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encqr.no_s_b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
