{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "from Losses import *\n",
    "from Metrics import evaluate, cross_bound_check\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# class TimeSeriesDataLoader:\n",
    "#     def __init__(self, data, window_size, label_column, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, scaler=None):\n",
    "#         self.data         = data\n",
    "#         self.window_size  = window_size\n",
    "#         self.label_column = label_column\n",
    "#         self.train_ratio  = train_ratio\n",
    "#         self.val_ratio    = val_ratio\n",
    "#         self.test_ratio   = test_ratio\n",
    "#         self.scaler       = scaler\n",
    "\n",
    "#         self.train_X, self.train_y = None, None\n",
    "#         self.val_X, self.val_y = None, None\n",
    "#         self.test_X, self.test_y = None, None\n",
    "\n",
    "#         self._prepare_data()\n",
    "\n",
    "#     def _prepare_data(self):\n",
    "#         # 删除缺失值\n",
    "#         self.data = self.data.dropna()\n",
    "\n",
    "#         # 划分特征和目标变量\n",
    "#         X = self.data.drop(columns=[self.label_column]).values\n",
    "#         y = self.data[self.label_column].values\n",
    "\n",
    "#         # 处理缺失值（如果有）\n",
    "#         # 进行标准化（如果需要）\n",
    "#         if self.scaler is None:\n",
    "#             self.scaler_x = StandardScaler()\n",
    "#             self.scaler_y = StandardScaler()\n",
    "#             X = self.scaler_x.fit_transform(X)\n",
    "#             y = self.scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "#         # 生成窗口数据\n",
    "#         sequences_X, sequences_y = [], []\n",
    "#         for i in range(len(self.data) - self.window_size + 1):\n",
    "#             window_X = X[i:i + self.window_size]\n",
    "#             window_y = y[i + self.window_size - 1]  # 取窗口最后一个样本作为目标变量\n",
    "#             sequences_X.append(window_X)\n",
    "#             sequences_y.append(window_y)\n",
    "#         sequences_X, sequences_y = np.array(sequences_X), np.array(sequences_y)\n",
    "#         sequences_X = sequences_X.reshape(len(sequences_X), self.window_size*sequences_X.shape[2])\n",
    "\n",
    "#         # 划分训练集、验证集、测试集\n",
    "#         train_size = int(len(sequences_X) * self.train_ratio)\n",
    "#         val_size = int(len(sequences_X) * self.val_ratio)\n",
    "#         test_size = len(sequences_X) - train_size - val_size\n",
    "\n",
    "#         self.train_X, self.train_y = sequences_X[:train_size], sequences_y[:train_size]\n",
    "#         self.val_X, self.val_y = sequences_X[train_size:train_size + val_size], sequences_y[train_size:train_size + val_size]\n",
    "#         self.test_X, self.test_y = sequences_X[train_size + val_size:], sequences_y[train_size + val_size:]\n",
    "\n",
    "#     def inverse_transform(self, data, is_label=False):\n",
    "#         # 将标准化后的数据还原\n",
    "#         if is_label:\n",
    "#             return self.scaler_y.inverse_transform(data.reshape(-1, 1)).flatten()\n",
    "#             # return self.scaler_y.inverse_transform(data)[:, 0]\n",
    "#         else:\n",
    "#             return self.scaler_x.inverse_transform(data)\n",
    "\n",
    "#     def get_train_data(self, to_tensor=False):\n",
    "#         if to_tensor:\n",
    "#             return torch.from_numpy(self.train_X).to(torch.float32), torch.from_numpy(self.train_y).to(torch.float32)\n",
    "#         else:\n",
    "#             return self.train_X, self.train_y\n",
    "\n",
    "#     def get_val_data(self, to_tensor=False):\n",
    "#         if to_tensor:\n",
    "#             return torch.from_numpy(self.val_X).to(torch.float32), torch.from_numpy(self.val_y).to(torch.float32)\n",
    "#         else:\n",
    "#             return self.val_X, self.val_y\n",
    "\n",
    "#     def get_test_data(self, to_tensor=False):\n",
    "#         if to_tensor:\n",
    "#             return torch.from_numpy(self.test_X).to(torch.float32), torch.from_numpy(self.test_y).to(torch.float32)\n",
    "#         else:\n",
    "#             return self.test_X, self.test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class TimeSeriesDataLoader:\n",
    "    def __init__(self, data, window_size, label_column, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, scaler=None):\n",
    "        self.data         = data\n",
    "        self.window_size  = window_size\n",
    "        self.label_column = label_column\n",
    "        self.train_ratio  = train_ratio\n",
    "        self.val_ratio    = val_ratio\n",
    "        self.test_ratio   = test_ratio\n",
    "        self.scaler       = scaler\n",
    "\n",
    "        self.train_X, self.train_y = None, None\n",
    "        self.val_X, self.val_y = None, None\n",
    "        self.test_X, self.test_y = None, None\n",
    "\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        # 删除缺失值\n",
    "        self.data = self.data.dropna()\n",
    "\n",
    "        # 划分特征和目标变量\n",
    "        X = self.data.drop(columns=[self.label_column]).values\n",
    "        y = self.data[self.label_column].values\n",
    "\n",
    "        # 处理缺失值（如果有）\n",
    "        # 进行标准化（如果需要）\n",
    "        if self.scaler is None:\n",
    "            self.scaler_x = StandardScaler()\n",
    "            self.scaler_y = StandardScaler()\n",
    "            X = self.scaler_x.fit_transform(X)\n",
    "            y = self.scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "        data = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
    "        # 生成窗口数据\n",
    "        sequences_X, sequences_y = [], []\n",
    "        for i in range(len(self.data) - self.window_size + 1):\n",
    "            window_X = data[i:i + self.window_size]\n",
    "            window_y = y[i + self.window_size - 1]  # 取窗口最后一个样本作为目标变量\n",
    "            sequences_X.append(window_X)\n",
    "            sequences_y.append(window_y)\n",
    "        sequences_X, sequences_y = np.array(sequences_X), np.array(sequences_y)\n",
    "        # print(f'x: {sequences_X.shape}, y: {sequences_y.shape}')\n",
    "        # sequences_X = np.concatenate((sequences_X, sequences_y.reshape(-1, 1)), axis=1)\n",
    "        sequences_X = sequences_X.reshape(len(sequences_X), self.window_size*sequences_X.shape[2])\n",
    "\n",
    "        # 划分训练集、验证集、测试集\n",
    "        train_size = int(len(sequences_X) * self.train_ratio)\n",
    "        val_size = int(len(sequences_X) * self.val_ratio)\n",
    "        test_size = len(sequences_X) - train_size - val_size\n",
    "\n",
    "        self.train_X, self.train_y = sequences_X[:train_size], sequences_y[:train_size]\n",
    "        self.val_X, self.val_y = sequences_X[train_size:train_size + val_size], sequences_y[train_size:train_size + val_size]\n",
    "        self.test_X, self.test_y = sequences_X[train_size + val_size:], sequences_y[train_size + val_size:]\n",
    "\n",
    "    def inverse_transform(self, data, is_label=True):\n",
    "        # 将标准化后的数据还原\n",
    "        if is_label:\n",
    "            if data.ndim < 2:\n",
    "                return self.scaler_y.inverse_transform(data.reshape(-1, 1)).flatten()\n",
    "            else:\n",
    "                for i in range(data.shape[1]):\n",
    "                    data[:, i] = self.scaler_y.inverse_transform(data[:, i].reshape(-1, 1)).flatten()\n",
    "                return data\n",
    "        else:\n",
    "            return self.scaler_x.inverse_transform(data)\n",
    "\n",
    "    def get_train_data(self, to_tensor=False):\n",
    "        if to_tensor:\n",
    "            return torch.from_numpy(self.train_X).to(torch.float32), torch.from_numpy(self.train_y).to(torch.float32)\n",
    "        else:\n",
    "            return self.train_X, self.train_y\n",
    "\n",
    "    def get_val_data(self, to_tensor=False):\n",
    "        if to_tensor:\n",
    "            return torch.from_numpy(self.val_X).to(torch.float32), torch.from_numpy(self.val_y).to(torch.float32)\n",
    "        else:\n",
    "            return self.val_X, self.val_y\n",
    "\n",
    "    def get_test_data(self, to_tensor=False):\n",
    "        if to_tensor:\n",
    "            return torch.from_numpy(self.test_X).to(torch.float32), torch.from_numpy(self.test_y).to(torch.float32)\n",
    "        else:\n",
    "            return self.test_X, self.test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActivePower</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDirection_sin</th>\n",
       "      <th>WindDirection_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>-5.357727</td>\n",
       "      <td>2.279088</td>\n",
       "      <td>0.989358</td>\n",
       "      <td>-0.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-5.822360</td>\n",
       "      <td>2.339343</td>\n",
       "      <td>-0.918521</td>\n",
       "      <td>0.395372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-5.279409</td>\n",
       "      <td>2.455610</td>\n",
       "      <td>0.650311</td>\n",
       "      <td>0.759668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-4.648054</td>\n",
       "      <td>2.026754</td>\n",
       "      <td>-0.543996</td>\n",
       "      <td>0.839088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-4.684632</td>\n",
       "      <td>1.831420</td>\n",
       "      <td>-0.543996</td>\n",
       "      <td>0.839088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ActivePower  WindSpeed  WindDirection_sin  WindDirection_cos\n",
       "144    -5.357727   2.279088           0.989358          -0.145500\n",
       "145    -5.822360   2.339343          -0.918521           0.395372\n",
       "146    -5.279409   2.455610           0.650311           0.759668\n",
       "147    -4.648054   2.026754          -0.543996           0.839088\n",
       "148    -4.684632   1.831420          -0.543996           0.839088"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/Kaggle Wind Power Forecasting Data/Turbine_Data.csv'\n",
    "df        = pd.read_csv(data_path, parse_dates=[\"Unnamed: 0\"])\n",
    "df        = df[['ActivePower', 'WindDirection','WindSpeed']]\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df['WindDirection_sin'] = np.sin(df['WindDirection'])\n",
    "df['WindDirection_cos'] = np.cos(df['WindDirection'])\n",
    "df.drop('WindDirection', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActivePower</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDirection_sin</th>\n",
       "      <th>WindDirection_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>360.848293</td>\n",
       "      <td>4.902579</td>\n",
       "      <td>0.030517</td>\n",
       "      <td>0.000677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>385.623285</td>\n",
       "      <td>1.710056</td>\n",
       "      <td>0.591279</td>\n",
       "      <td>0.806199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-10.476446</td>\n",
       "      <td>1.306637</td>\n",
       "      <td>-0.999981</td>\n",
       "      <td>-0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.966478</td>\n",
       "      <td>3.530923</td>\n",
       "      <td>-0.387809</td>\n",
       "      <td>-0.899880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>237.797081</td>\n",
       "      <td>4.765032</td>\n",
       "      <td>0.017672</td>\n",
       "      <td>0.030945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>545.578402</td>\n",
       "      <td>6.186512</td>\n",
       "      <td>0.510164</td>\n",
       "      <td>0.895984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1713.238386</td>\n",
       "      <td>9.078578</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ActivePower    WindSpeed  WindDirection_sin  WindDirection_cos\n",
       "count  2000.000000  2000.000000        2000.000000        2000.000000\n",
       "mean    360.848293     4.902579           0.030517           0.000677\n",
       "std     385.623285     1.710056           0.591279           0.806199\n",
       "min     -10.476446     1.306637          -0.999981          -0.999999\n",
       "25%      48.966478     3.530923          -0.387809          -0.899880\n",
       "50%     237.797081     4.765032           0.017672           0.030945\n",
       "75%     545.578402     6.186512           0.510164           0.895984\n",
       "max    1713.238386     9.078578           0.999998           1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:2000]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1399, 8) (1399,)\n",
      "(299, 8) (299,)\n",
      "(301, 8) (301,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "label_column = 'ActivePower'\n",
    "\n",
    "loader = TimeSeriesDataLoader(df, window_size, label_column)\n",
    "X_train, Y_train = loader.get_train_data()\n",
    "X_val  , Y_val   = loader.get_val_data()\n",
    "X_test , Y_test  = loader.get_test_data()\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_val.shape, Y_val.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import QuantileRegressionEstimator\n",
    "from Losses import PinballLoss\n",
    "\n",
    "class NESCQR:\n",
    "    def __init__(self, data_loader, model_pool:list, label_pool:list, batch_size:int, M:int, alpha_set:list, \n",
    "                 l_rate:float, max_epochs:int, replace, symmetric, saveflag, save_dir, \n",
    "                 alpha_base=None, step=2, device='cuda', verbose=True):\n",
    "        assert 0 < M <= len(model_pool), \"M must be in range (0, len(model_pool)]\"\n",
    "        self.data_loader = data_loader\n",
    "        self.model_pool  = model_pool\n",
    "        self.label_pool  = label_pool  # 与model_pool里每个模型一一对应的模型名字\n",
    "        self.batch_size  = batch_size\n",
    "        self.M           = M           # 最终的集成模型的基学习器个数\n",
    "        self.alpha_set   = alpha_set   # 置信水平集合\n",
    "        self.l_rate      = l_rate      # 学习率\n",
    "        self.max_epochs  = max_epochs\n",
    "        self.device      = device\n",
    "        self.saveflag   = saveflag\n",
    "        self.save_dir    = save_dir\n",
    "        self.alpha_base  = alpha_base if alpha_base else max(alpha_set)\n",
    "        self.quantiles   = [self.alpha_base / 2, 1 - self.alpha_base / 2]\n",
    "        self.loss_fn     = PinballLoss(self.quantiles, self.device)\n",
    "        self.replace     = replace    # 是否有放回地前向选择\n",
    "        self.step        = step       # DMCQR算法更新步长，int, 越小更新越快越准确\n",
    "        self.symmetric   = symmetric  # 是否采用对称性conformity score\n",
    "        # self.logger      = logger\n",
    "        self.verbose     = verbose\n",
    "        \n",
    "    def init_training(self, saveflag=False):\n",
    "        # 先训练好每个基学习器\n",
    "        X_train, Y_train = self.data_loader.get_train_data(to_tensor=True)\n",
    "        X_val  , Y_val   = self.data_loader.get_val_data(to_tensor=True)\n",
    "        # X_train, Y_train = X_train.to(self.device), Y_train.to(self.device)\n",
    "        # X_val  , Y_val   = X_val.to(self.device), Y_val.to(self.device)\n",
    "\n",
    "        assert len(X_train) == len(Y_train)\n",
    "        assert len(X_val)   == len(Y_val)\n",
    "        assert len(X_test)  == len(Y_test)\n",
    "\n",
    "        print(f'X_train.shape: {X_train.shape}, Y_train.shape: {Y_train.shape}')\n",
    "        print(f'X_val.shape: {X_val.shape}, Y_val.shape: {Y_val.shape}')\n",
    "        # print(f'X_test.shape: {X_test.shape}, Y_train.shape: {Y_test.shape}')\n",
    "\n",
    "        num_models = len(self.model_pool)\n",
    "        model_pool_trained = []\n",
    "        for i, model in enumerate(self.model_pool):\n",
    "            print(f'Model {i+1}/{num_models} {self.label_pool[i]} starts training...')\n",
    "\n",
    "            # 采用DMCQR得到最终的预测区间，则只需要最大的alpha，即两条分位数即可得到多条预测区间上下界。\n",
    "            learner = QuantileRegressionEstimator(model, [max(self.alpha_set)], self.max_epochs,\n",
    "                                                   self.batch_size,self.device, self.l_rate, self.verbose)\n",
    "            learner.fit(X_train, Y_train, X_val, Y_val)\n",
    "            model_pool_trained.append(learner)\n",
    "            print(f'Model {i+1}/{num_models} {self.label_pool[i]} finished training.')\n",
    "            \n",
    "            if saveflag:\n",
    "                torch.save(learner, f'{self.save_dir}/trained_models/{self.label_pool[i]}.pth')\n",
    "                print(f'Model {i+1}/{num_models} saved.')\n",
    "\n",
    "        return model_pool_trained\n",
    "\n",
    "    def forward_selection(self, model_pool_trained, label_pool, replace=True):\n",
    "        # 前向选择出最优集成模型组合\n",
    "        X_val  , Y_val   = self.data_loader.get_val_data(to_tensor=True)\n",
    "        X_val  , Y_val   = X_val.to(self.device), Y_val.to(self.device)\n",
    "        # pool = dict(zip(label_pool, model_pool_trained))\n",
    "        if replace:\n",
    "            print('Forward selection with replacement.')\n",
    "        else:\n",
    "            print('Forward selection without replacement.')\n",
    "\n",
    "        selected_model, selected_label = [], []\n",
    "        while len(selected_model) < self.M:\n",
    "            best_loss = np.inf\n",
    "            \n",
    "            for i in range(len(model_pool_trained)):\n",
    "                models_ = selected_model + [model_pool_trained[i]]\n",
    "                merged_output = torch.stack([torch.from_numpy(model.predict(X_val)) for model in models_])\n",
    "                merged_output = torch.mean(merged_output, axis=0)\n",
    "                loss = self.loss_fn(merged_output, Y_val)\n",
    "                if loss.item() < best_loss:\n",
    "                    best_model = model_pool_trained[i]\n",
    "                    best_loss  = loss.item()\n",
    "                    best_label = i\n",
    "\n",
    "            selected_model.append(best_model)\n",
    "            selected_label.append(label_pool[best_label])\n",
    "            if not replace:  # 无放回\n",
    "                model_pool_trained.pop(best_label)\n",
    "                \n",
    "        print(f'Model selected: {selected_label}')\n",
    "\n",
    "        return selected_model, selected_label\n",
    "\n",
    "    def conformal(self, res_val, Y_val, res_test, Y_test, step, symmetric=True):\n",
    "        # DMCQR\n",
    "        assert res_val.shape[0] == Y_val.shape[0]\n",
    "        assert res_val.shape[1] == 2\n",
    "        assert res_test.shape[1] == 2\n",
    "\n",
    "        Y_val  , Y_test   = np.array(Y_val),   np.array(Y_test)\n",
    "        res_val, res_test = np.array(res_val), np.array(res_test)\n",
    "        Y_all     = np.concatenate((Y_val, Y_test), axis=0)\n",
    "        res_all   = np.concatenate((res_val, res_test), axis=0)\n",
    "        num_alpha = len(self.alpha_set)\n",
    "        conf_PI   = np.zeros((len(res_test), num_alpha*2))\n",
    "        val_size  = len(Y_val)\n",
    "        test_size = len(Y_test)\n",
    "\n",
    "        if symmetric:  \n",
    "            # DMCQRS, use symmetric conformity score, 对称误差集合\n",
    "            print('Use symmetric conformity score to calibrate quantiles.')\n",
    "            E = list(np.max((res_val[:, 0] - Y_val, Y_val - res_val[:, -1]), axis=0))  # 误差集合，队列，先进先出\n",
    "            Q = np.zeros(num_alpha)\n",
    "\n",
    "            for t in range(val_size, val_size + test_size):\n",
    "                for i, alpha in enumerate(self.alpha_set):\n",
    "                    Q[i] = np.quantile(E, (1-alpha)*(1+1/val_size))\n",
    "                    conf_PI[:, i] = res_test[:, 0] - Q[i]\n",
    "                    conf_PI[:, -(i+1)] = res_test[:, -1] + Q[i]\n",
    "\n",
    "                    if t % step == 0:\n",
    "                        # print(f't = {t}, Q = {Q}')\n",
    "                        for j in range(t - self.step, t - 1):\n",
    "                            e = np.max((res_all[j, 0] - Y_all[j], Y_all[j] - res_all[j, -1]),axis=0)\n",
    "                            E.pop(0)\n",
    "                            E.append(e)   \n",
    "\n",
    "            return conf_PI\n",
    "        \n",
    "        else:   \n",
    "            # DMCQRS, use asymmetric conformity score, 非对称误差集合\n",
    "            print('Use asymmetric conformity score to calibrate quantiles.')\n",
    "            Q_low, Q_high = np.zeros(num_alpha), np.zeros(num_alpha)\n",
    "            E_low = list(res_val[:, 0] - Y_val)    # 下界误差集合\n",
    "            E_high = list(Y_val - res_val[:,-1])   # 上界误差集合\n",
    "                \n",
    "            for t in range(val_size, val_size + test_size):\n",
    "                for i, alpha in enumerate(self.alpha_set):\n",
    "                    Q_low[i] = np.quantile(E_low, (1 - alpha / 2))\n",
    "                    Q_high[-(i+1)] = np.quantile(E_high, (1 - alpha / 2))\n",
    "                    \n",
    "                    conf_PI[:, i] = res_test[:, 0] - Q_low[i]\n",
    "                    conf_PI[:, -(i+1)] = res_test[:, -1] + Q_high[-(i+1)]\n",
    "\n",
    "                if t % step == 0:\n",
    "                    # print(f't: {t}, Q_low: {Q_low}, Q_high: {Q_high}')\n",
    "                    for j in range(t - step, t - 1):\n",
    "                        e_low = res_all[j, 0] - Y_all[j]\n",
    "                        e_high = Y_all[j] - res_all[j, -1]\n",
    "                        E_low.pop(0)\n",
    "                        E_low.append(e_low)\n",
    "                        E_high.pop(0)\n",
    "                        E_high.append(e_high)\n",
    "\n",
    "            return conf_PI     \n",
    "\n",
    "    def fit(self):\n",
    "        model_pool_trained = self.init_training()\n",
    "        self.model_pool_selected, self.selected_label = self.forward_selection(model_pool_trained, self.label_pool, self.replace)\n",
    "\n",
    "    def predict(self, X_test=None, Y_test=None, inverse_normalization=True):\n",
    "        # construct prediction intervals\n",
    "        X_val  , Y_val   = self.data_loader.get_val_data(to_tensor=True)\n",
    "        if not X_test:\n",
    "            X_test,  Y_test  = self.data_loader.get_test_data(to_tensor=True)\n",
    "        Y_val  , Y_test  = Y_val.detach().numpy(), Y_test.detach().numpy()\n",
    "        X_val   = X_val.to(self.device)\n",
    "        X_test  = X_test.to(self.device)\n",
    "\n",
    "        pred = self.model_pool_selected[0].predict(X_val)\n",
    "        # print(f'pred.shape: {pred.shape}')\n",
    "        res_val = torch.stack([torch.from_numpy(model.predict(X_val)) for model in self.model_pool_selected])\n",
    "        res_val = torch.mean(res_val, axis=0)\n",
    "        res_val = res_val.detach().numpy()\n",
    "        res_test = torch.stack([torch.from_numpy(model.predict(X_test)) for model in self.model_pool_selected])\n",
    "        res_test = torch.mean(res_test, axis=0)\n",
    "        res_test = res_test.detach().numpy()\n",
    "        # print(f'res_val.shape: {res_val.shape}, res_test.shape: {res_test.shape}')\n",
    "\n",
    "        self.conf_PI = self.conformal(res_val, Y_val, res_test, Y_test, self.step, self.symmetric)\n",
    "        if inverse_normalization:  # 逆标准化回原来的量纲\n",
    "            self.conf_PI = self.data_loader.inverse_transform(self.conf_PI, is_label=True)\n",
    "\n",
    "        cols = [str(round(alpha/2, 3)) for alpha in self.alpha_set] + [str(round(1-alpha/2, 3)) for alpha in self.alpha_set]\n",
    "        if self.saveflag:\n",
    "            df = pd.DataFrame(self.conf_PI, columns=cols)\n",
    "            df.to_csv(os.path.join(self.save_dir,'conf_PIs.csv'), index=False)\n",
    "            \n",
    "        return self.conf_PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\\2023_10_08_18_00_23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Postgraduate\\papers\\NESCQR\\code\\NESCQR\\venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "# 获取当前时间戳\n",
    "current_time = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "# 构建文件夹路径\n",
    "save_dir = os.path.join(\"result\", current_time)\n",
    "print(save_dir)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "n_ensemble = 3  #number of baseline models, which is M in paper.\n",
    "M          = n_ensemble\n",
    "max_epochs = 500\n",
    "l_rate     = 1e-4\n",
    "activation = 'tanh'  #nn.Tanh,              nn.ReLU, nn.Sigmoid\n",
    "batch_size = 512\n",
    "dropout    = 0.2\n",
    "replace    = False\n",
    "symmetric  = True\n",
    "saveflag   = True\n",
    "# save_dir   = './results/'\n",
    "step       = 2\n",
    "device     = 'cuda'\n",
    "verbose    = True\n",
    "\n",
    "alpha_set = np.array([0.05, 0.10, 0.15])\n",
    "num_alpha = len(alpha_set)\n",
    "alpha_base = max(alpha_set)\n",
    "quantiles = [max(alpha_set)/2, 1 - max(alpha_set)/2]\n",
    "# quantiles = np.zeros(2*num_alpha)\n",
    "# for i in range(num_alpha):\n",
    "#     quantiles[i] = alpha_set[i] / 2\n",
    "#     quantiles[-(i+1)] = 1 - alpha_set[i] / 2\n",
    "\n",
    "# loss_fn = PinballLoss(quantiles=quantiles, device=device)\n",
    "input_dim = X_train.shape[1]\n",
    "x_size = len(df.columns)\n",
    "out_dim = len(quantiles)\n",
    "kernel_size = 2\n",
    "num_repeat = 1\n",
    "hidden_units = [20 + i*4 for i in range(num_repeat)]\n",
    "channel_sizes = [3 + i*2 for i in range(num_repeat)]\n",
    "\n",
    "model_pool = [NET(input_dim, h, out_dim, activation) for h in hidden_units] + \\\n",
    "             [RNN(input_dim, h, out_dim, activation, device) for h in hidden_units] + \\\n",
    "             [LSTM(input_dim, h, out_dim, device) for h in hidden_units] + \\\n",
    "             [GRU(x_size, h, out_dim, device) for h in hidden_units] + \\\n",
    "             [TCN(x_size, out_dim, [c]*2, kernel_size, dropout) for c in channel_sizes]\n",
    "             \n",
    "# label_pool = ['BPNN']*num_repeat + ['RNN']*num_repeat + ['LSTM']*num_repeat + ['GRU']*num_repeat + ['TCN']*num_repeat\n",
    "label_pool = [f'BPNN_{h}' for h in hidden_units] + \\\n",
    "             [f'RNN_{h}' for h in hidden_units] + \\\n",
    "             [f'LSTM_{h}' for h in hidden_units] + \\\n",
    "             [f'GRU_{h}' for h in hidden_units] + \\\n",
    "             [f'TCN_{c}' for c in channel_sizes]\n",
    "\n",
    "nescqr = NESCQR(loader, model_pool, label_pool, batch_size, M, alpha_set, \n",
    "                 l_rate, max_epochs, replace, symmetric, saveflag, save_dir, alpha_base, step, \n",
    "                  device, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: torch.Size([1399, 8]), Y_train.shape: torch.Size([1399])\n",
      "X_val.shape: torch.Size([299, 8]), Y_val.shape: torch.Size([299])\n",
      "Model 1/5 BPNN_20 starts training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100, train_loss: 0.3112, validation_loss: 0.3040, cost_time: 0.03s\n",
      "Epoch:200, train_loss: 0.2083, validation_loss: 0.1849, cost_time: 0.03s\n",
      "Epoch:300, train_loss: 0.1564, validation_loss: 0.1211, cost_time: 0.04s\n",
      "Epoch:400, train_loss: 0.1218, validation_loss: 0.0952, cost_time: 0.03s\n",
      "Epoch:500, train_loss: 0.1043, validation_loss: 0.0828, cost_time: 0.03s\n",
      "Model 1/5 BPNN_20 finished training.\n",
      "Model 2/5 RNN_20 starts training...\n",
      "Epoch:100, train_loss: 0.3388, validation_loss: 0.3471, cost_time: 0.04s\n",
      "Epoch:200, train_loss: 0.2279, validation_loss: 0.2486, cost_time: 0.03s\n",
      "Epoch:300, train_loss: 0.1476, validation_loss: 0.1736, cost_time: 0.03s\n",
      "Epoch:400, train_loss: 0.1012, validation_loss: 0.1198, cost_time: 0.03s\n",
      "Epoch:500, train_loss: 0.0766, validation_loss: 0.0891, cost_time: 0.04s\n",
      "Model 2/5 RNN_20 finished training.\n",
      "Model 3/5 LSTM_20 starts training...\n",
      "Epoch:100, train_loss: 0.3838, validation_loss: 0.3759, cost_time: 0.03s\n",
      "Epoch:200, train_loss: 0.2986, validation_loss: 0.2978, cost_time: 0.03s\n",
      "Epoch:300, train_loss: 0.2007, validation_loss: 0.2122, cost_time: 0.03s\n",
      "Epoch:400, train_loss: 0.1245, validation_loss: 0.1417, cost_time: 0.03s\n",
      "Epoch:500, train_loss: 0.0887, validation_loss: 0.1046, cost_time: 0.03s\n",
      "Model 3/5 LSTM_20 finished training.\n",
      "Model 4/5 GRU_20 starts training...\n",
      "Epoch:100, train_loss: 0.2777, validation_loss: 0.2764, cost_time: 0.04s\n",
      "Epoch:200, train_loss: 0.1794, validation_loss: 0.1884, cost_time: 0.04s\n",
      "Epoch:300, train_loss: 0.1150, validation_loss: 0.1274, cost_time: 0.03s\n",
      "Epoch:400, train_loss: 0.0857, validation_loss: 0.0930, cost_time: 0.03s\n",
      "Epoch:500, train_loss: 0.0725, validation_loss: 0.0763, cost_time: 0.04s\n",
      "Model 4/5 GRU_20 finished training.\n",
      "Model 5/5 TCN_3 starts training...\n",
      "Epoch:100, train_loss: 0.2225, validation_loss: 0.2342, cost_time: 0.04s\n",
      "Epoch:200, train_loss: 0.1784, validation_loss: 0.1943, cost_time: 0.04s\n",
      "Epoch:300, train_loss: 0.1404, validation_loss: 0.1553, cost_time: 0.04s\n",
      "Epoch:400, train_loss: 0.1087, validation_loss: 0.1138, cost_time: 0.04s\n",
      "Epoch:500, train_loss: 0.0972, validation_loss: 0.0932, cost_time: 0.04s\n",
      "Model 5/5 TCN_3 finished training.\n",
      "Forward selection without replacement.\n",
      "Model selected: ['GRU_20', 'BPNN_20', 'LSTM_20']\n",
      "Use symmetric conformity score to calibrate quantiles.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(301, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test , Y_test  = loader.get_test_data(to_tensor=True)\n",
    "nescqr.fit()\n",
    "conf_PI = nescqr.predict()\n",
    "conf_PI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([237.34871709, 250.13931448, 271.58052059, 728.84945852,\n",
       "       750.29067612, 763.08126202])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_PI[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Metrics import *\n",
    "\n",
    "# def evaluate(y_test, PIs, alpha_set, ita=0.5, saveflag=False, save_dir=None, verbose=True):\n",
    "#     \"\"\"\n",
    "#     对所有预测区间进行评估。\n",
    "\n",
    "#     Args:\n",
    "#     y_test: 测试集的y, the ground truth.\n",
    "#     PIs: 预测区间，从左到右依次增大，prediction intervals, ndarray.\n",
    "#     alpha_set: 置信水平集合, the set of alphas.\n",
    "#     ita: CWC中的一个参数，控制惩罚项的大小，注意这里的PICP和PINC均乘了100，所以这个参数不需要太大。\n",
    "#     verbose: 是否输出详细信息。\n",
    "    \n",
    "#     out:\n",
    "#     df: 包括回归和区间的评估的结果, DataFrame\n",
    "    \n",
    "#     \"\"\"\n",
    "#     assert PIs.shape[1] == len(alpha_set) * 2\n",
    "#     y_test = np.array(y_test)\n",
    "#     if y_test.ndim > 1:\n",
    "#         y_test = y_test.squeeze()\n",
    "    \n",
    "#     result = []\n",
    "#     for i, alpha in enumerate(alpha_set):\n",
    "#         y_lower, y_upper = PIs[:, i], PIs[:, -(i+1)]\n",
    "#         y_pred = (y_lower + y_upper) / 2   # Regression prediction\n",
    "#         PINC = (1 - alpha) * 100\n",
    "    \n",
    "#         # Regression\n",
    "#         MSE = mean_squared_error(y_pred, y_test)\n",
    "#         MAE = mean_absolute_error(y_pred, y_test)\n",
    "#         RMSE = np.sqrt(MSE)\n",
    "#         CRPS = crps(y_pred, y_test)\n",
    "#         SDE = sde(y_pred, y_test)\n",
    "\n",
    "#         # Interval prediction\n",
    "#         in_the_range = np.sum((y_test >= y_lower) & (y_test <= y_upper))\n",
    "#         PICP = in_the_range / len(y_test) * 100\n",
    "#         MPIW  = np.mean(abs(y_upper - y_lower))\n",
    "#         PINAW = MPIW / (y_test.max() - y_test.min())\n",
    "#         F = 2 * PICP * (1/MPIW) / (PICP + 1 / MPIW)\n",
    "#         ACE = PICP - PINC\n",
    "#         gamma = 1 if ACE < 0 else 0\n",
    "#         CWC = PINAW * (1 + gamma * np.exp(-ita*ACE))\n",
    "#         score = interval_score(y_test, y_lower, y_upper, alpha)\n",
    "\n",
    "#         if verbose:\n",
    "#             print('PINC: {:.0f}%, MAE: {:.4f}, MSE: {:.4f}, RMSE: {:.4f}, CRPS: {:.4f}, SDE: {:.4f}'.format(PINC, MAE,\n",
    "#                                             MSE, RMSE, CRPS, SDE))\n",
    "#             print('PINC: {:.0f}%, PICP: {:.4f}, MPIW: {:.4f}, PINAW: {:.4f}, F: {:.4f}, ACE: {:.4f}, CWC: {:.4f}, \\\n",
    "#                   interval_score: {:.4f}'.format(PINC, PICP, MPIW, PINAW, F, ACE, CWC, score))\n",
    "#         result.append([PINC, MAE, MSE, RMSE, CRPS, SDE, PICP, MPIW, F, PINAW, ACE, CWC, score])\n",
    "\n",
    "#     result_df = pd.DataFrame(result, columns=['PINC','MAE', 'MSE', 'RMSE', 'CRPS', 'SDE', 'PICP', 'MPIW', 'F', 'PINAW', 'ACE', 'CWC', 'Interval score'])\n",
    "#     if saveflag:\n",
    "#         result_df.to_csv(os.path.join(save_dir, 'metrics.csv'))\n",
    "#         print('Metrics are saved to {}'.format(os.path.join(save_dir, 'metrics.csv')))\n",
    "#         return result_df\n",
    "#     else:\n",
    "#         return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINC: 95%, MAE: 128.4229, MSE: 22873.5461, RMSE: 151.2400, CRPS: 128.4229, SDE: 144.5217\n",
      "PINC: 95%, PICP: 95.6811, MPIW: 486.6723, PINAW: 0.4191, F: 0.0041, ACE: 0.6811, CWC: 0.4191,                   interval_score: 543.6325\n",
      "PINC: 90%, MAE: 128.4229, MSE: 22873.5450, RMSE: 151.2400, CRPS: 128.4229, SDE: 144.5217\n",
      "PINC: 90%, PICP: 93.6877, MPIW: 461.0912, PINAW: 0.3970, F: 0.0043, ACE: 3.6877, CWC: 0.3970,                   interval_score: 502.9226\n",
      "PINC: 85%, MAE: 128.4229, MSE: 22873.5452, RMSE: 151.2400, CRPS: 128.4229, SDE: 144.5217\n",
      "PINC: 85%, PICP: 88.7043, MPIW: 418.2087, PINAW: 0.3601, F: 0.0048, ACE: 3.7043, CWC: 0.3601,                   interval_score: 472.1707\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINC</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>CRPS</th>\n",
       "      <th>SDE</th>\n",
       "      <th>PICP</th>\n",
       "      <th>MPIW</th>\n",
       "      <th>F</th>\n",
       "      <th>PINAW</th>\n",
       "      <th>ACE</th>\n",
       "      <th>CWC</th>\n",
       "      <th>Interval score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.0</td>\n",
       "      <td>128.422940</td>\n",
       "      <td>22873.546132</td>\n",
       "      <td>151.240028</td>\n",
       "      <td>128.422940</td>\n",
       "      <td>144.521674</td>\n",
       "      <td>95.681063</td>\n",
       "      <td>486.672334</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.419051</td>\n",
       "      <td>0.681063</td>\n",
       "      <td>0.419051</td>\n",
       "      <td>543.632499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.0</td>\n",
       "      <td>128.422936</td>\n",
       "      <td>22873.544981</td>\n",
       "      <td>151.240024</td>\n",
       "      <td>128.422936</td>\n",
       "      <td>144.521670</td>\n",
       "      <td>93.687708</td>\n",
       "      <td>461.091150</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.397025</td>\n",
       "      <td>3.687708</td>\n",
       "      <td>0.397025</td>\n",
       "      <td>502.922608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.0</td>\n",
       "      <td>128.422938</td>\n",
       "      <td>22873.545200</td>\n",
       "      <td>151.240025</td>\n",
       "      <td>128.422938</td>\n",
       "      <td>144.521670</td>\n",
       "      <td>88.704319</td>\n",
       "      <td>418.208737</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.360101</td>\n",
       "      <td>3.704319</td>\n",
       "      <td>0.360101</td>\n",
       "      <td>472.170743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PINC         MAE           MSE        RMSE        CRPS         SDE  \\\n",
       "0  95.0  128.422940  22873.546132  151.240028  128.422940  144.521674   \n",
       "1  90.0  128.422936  22873.544981  151.240024  128.422936  144.521670   \n",
       "2  85.0  128.422938  22873.545200  151.240025  128.422938  144.521670   \n",
       "\n",
       "        PICP        MPIW         F     PINAW       ACE       CWC  \\\n",
       "0  95.681063  486.672334  0.004109  0.419051  0.681063  0.419051   \n",
       "1  93.687708  461.091150  0.004337  0.397025  3.687708  0.397025   \n",
       "2  88.704319  418.208737  0.004782  0.360101  3.704319  0.360101   \n",
       "\n",
       "   Interval score  \n",
       "0      543.632499  \n",
       "1      502.922608  \n",
       "2      472.170743  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_original = loader.inverse_transform(Y_test)\n",
    "res = evaluate(Y_test_original, conf_PI, alpha_set)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = 0, l1 = 0.0000, u1 = 0.0000\n",
      "r = 1, l1 = 0.0000, u1 = 0.0000\n",
      "No cross-bound phenomenon.\n",
      "MUCW = 0.0000, MLCW = 0.0000\n",
      "Cross loss:  0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUCW</th>\n",
       "      <th>MLCW</th>\n",
       "      <th>Cross loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MUCW  MLCW  Cross loss\n",
       "0     0     0         0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cross = cross_bound_check(conf_PI)\n",
    "res_cross"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
