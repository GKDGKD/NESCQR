{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "from Losses import *\n",
    "from Metrics import evaluate, cross_bound_check\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataLoader:\n",
    "    def __init__(self, data, window_size, label_column, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, scaler=None):\n",
    "        self.data         = data\n",
    "        self.window_size  = window_size\n",
    "        self.label_column = label_column\n",
    "        self.train_ratio  = train_ratio\n",
    "        self.val_ratio    = val_ratio\n",
    "        self.test_ratio   = test_ratio\n",
    "        self.scaler       = scaler\n",
    "\n",
    "        self.train_X, self.train_y = None, None\n",
    "        self.val_X, self.val_y = None, None\n",
    "        self.test_X, self.test_y = None, None\n",
    "\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        # 删除缺失值\n",
    "        self.data = self.data.dropna()\n",
    "\n",
    "        # 划分特征和目标变量\n",
    "        X = self.data.drop(columns=[self.label_column]).values\n",
    "        y = self.data[self.label_column].values\n",
    "\n",
    "        # 处理缺失值（如果有）\n",
    "        # 进行标准化（如果需要）\n",
    "        if self.scaler is None:\n",
    "            self.scaler_x = StandardScaler()\n",
    "            self.scaler_y = StandardScaler()\n",
    "            X = self.scaler_x.fit_transform(X)\n",
    "            y = self.scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "        data = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
    "        # 生成窗口数据\n",
    "        sequences_X, sequences_y = [], []\n",
    "        for i in range(len(self.data) - self.window_size + 1):\n",
    "            window_X = data[i:i + self.window_size]\n",
    "            window_y = y[i + self.window_size - 1]  # 取窗口最后一个样本作为目标变量\n",
    "            sequences_X.append(window_X)\n",
    "            sequences_y.append(window_y)\n",
    "        sequences_X, sequences_y = np.array(sequences_X), np.array(sequences_y)\n",
    "        # print(f'x: {sequences_X.shape}, y: {sequences_y.shape}')\n",
    "        # sequences_X = np.concatenate((sequences_X, sequences_y.reshape(-1, 1)), axis=1)\n",
    "        sequences_X = sequences_X.reshape(len(sequences_X), self.window_size*sequences_X.shape[2])\n",
    "\n",
    "        # 划分训练集、验证集、测试集\n",
    "        train_size = int(len(sequences_X) * self.train_ratio)\n",
    "        val_size = int(len(sequences_X) * self.val_ratio)\n",
    "        test_size = len(sequences_X) - train_size - val_size\n",
    "\n",
    "        self.train_X, self.train_y = sequences_X[:train_size], sequences_y[:train_size]\n",
    "        self.val_X, self.val_y = sequences_X[train_size:train_size + val_size], sequences_y[train_size:train_size + val_size]\n",
    "        self.test_X, self.test_y = sequences_X[train_size + val_size:], sequences_y[train_size + val_size:]\n",
    "\n",
    "    def inverse_transform(self, data, is_label=True):\n",
    "        # 将标准化后的数据还原\n",
    "        if is_label:\n",
    "            if data.ndim < 2:\n",
    "                return self.scaler_y.inverse_transform(data.reshape(-1, 1)).flatten()\n",
    "            else:\n",
    "                for i in range(data.shape[1]):\n",
    "                    data[:, i] = self.scaler_y.inverse_transform(data[:, i].reshape(-1, 1)).flatten()\n",
    "                return data\n",
    "        else:\n",
    "            return self.scaler_x.inverse_transform(data)\n",
    "\n",
    "    def get_train_data(self, to_tensor=False):\n",
    "        if to_tensor:\n",
    "            return torch.from_numpy(self.train_X).to(torch.float32), torch.from_numpy(self.train_y).to(torch.float32)\n",
    "        else:\n",
    "            return self.train_X, self.train_y\n",
    "\n",
    "    def get_val_data(self, to_tensor=False):\n",
    "        if to_tensor:\n",
    "            return torch.from_numpy(self.val_X).to(torch.float32), torch.from_numpy(self.val_y).to(torch.float32)\n",
    "        else:\n",
    "            return self.val_X, self.val_y\n",
    "\n",
    "    def get_test_data(self, to_tensor=False):\n",
    "        if to_tensor:\n",
    "            return torch.from_numpy(self.test_X).to(torch.float32), torch.from_numpy(self.test_y).to(torch.float32)\n",
    "        else:\n",
    "            return self.test_X, self.test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActivePower</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDirection_sin</th>\n",
       "      <th>WindDirection_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72162.000000</td>\n",
       "      <td>72162.000000</td>\n",
       "      <td>72162.000000</td>\n",
       "      <td>72162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>572.129599</td>\n",
       "      <td>5.696706</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>595.556861</td>\n",
       "      <td>2.619927</td>\n",
       "      <td>0.687171</td>\n",
       "      <td>0.726505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-38.524659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.999998</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.347222</td>\n",
       "      <td>3.651712</td>\n",
       "      <td>-0.666370</td>\n",
       "      <td>-0.724097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>351.279387</td>\n",
       "      <td>5.330200</td>\n",
       "      <td>-0.026521</td>\n",
       "      <td>-0.013277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>961.237629</td>\n",
       "      <td>7.239115</td>\n",
       "      <td>0.683262</td>\n",
       "      <td>0.739171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1779.032433</td>\n",
       "      <td>22.970893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ActivePower     WindSpeed  WindDirection_sin  WindDirection_cos\n",
       "count  72162.000000  72162.000000       72162.000000       72162.000000\n",
       "mean     572.129599      5.696706           0.000225           0.000490\n",
       "std      595.556861      2.619927           0.687171           0.726505\n",
       "min      -38.524659      0.000000          -0.999998          -1.000000\n",
       "25%       51.347222      3.651712          -0.666370          -0.724097\n",
       "50%      351.279387      5.330200          -0.026521          -0.013277\n",
       "75%      961.237629      7.239115           0.683262           0.739171\n",
       "max     1779.032433     22.970893           1.000000           1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/Kaggle Wind Power Forecasting Data/Turbine_Data.csv'\n",
    "df        = pd.read_csv(data_path, parse_dates=[\"Unnamed: 0\"])\n",
    "df        = df[['ActivePower', 'WindDirection','WindSpeed']]\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df['WindDirection_sin'] = np.sin(df['WindDirection'])\n",
    "df['WindDirection_cos'] = np.cos(df['WindDirection'])\n",
    "df.drop('WindDirection', axis=1, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActivePower</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDirection_sin</th>\n",
       "      <th>WindDirection_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>381.634134</td>\n",
       "      <td>4.959830</td>\n",
       "      <td>0.051187</td>\n",
       "      <td>-0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>393.655087</td>\n",
       "      <td>1.723514</td>\n",
       "      <td>0.600078</td>\n",
       "      <td>0.798927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-10.175428</td>\n",
       "      <td>1.306637</td>\n",
       "      <td>-0.999981</td>\n",
       "      <td>-0.999912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.539986</td>\n",
       "      <td>3.558236</td>\n",
       "      <td>-0.387809</td>\n",
       "      <td>-0.871058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>263.965496</td>\n",
       "      <td>4.889602</td>\n",
       "      <td>0.123603</td>\n",
       "      <td>0.044258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>610.756459</td>\n",
       "      <td>6.309334</td>\n",
       "      <td>0.514004</td>\n",
       "      <td>0.857788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1706.169049</td>\n",
       "      <td>9.078578</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ActivePower    WindSpeed  WindDirection_sin  WindDirection_cos\n",
       "count  1000.000000  1000.000000        1000.000000        1000.000000\n",
       "mean    381.634134     4.959830           0.051187          -0.000138\n",
       "std     393.655087     1.723514           0.600078           0.798927\n",
       "min     -10.175428     1.306637          -0.999981          -0.999912\n",
       "25%      53.539986     3.558236          -0.387809          -0.871058\n",
       "50%     263.965496     4.889602           0.123603           0.044258\n",
       "75%     610.756459     6.309334           0.514004           0.857788\n",
       "max    1706.169049     9.078578           0.999998           1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:1000]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 8) (699,)\n",
      "(149, 8) (149,)\n",
      "(151, 8) (151,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "label_column = 'ActivePower'\n",
    "\n",
    "loader = TimeSeriesDataLoader(df, window_size, label_column)\n",
    "X_train, Y_train = loader.get_train_data()\n",
    "X_val  , Y_val   = loader.get_val_data()\n",
    "X_test , Y_test  = loader.get_test_data()\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_val.shape, Y_val.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NESCQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import QuantileRegressionEstimator\n",
    "from Losses import PinballLoss\n",
    "\n",
    "class NESCQR:\n",
    "    def __init__(self, data_loader, model_pool:list, label_pool:list, batch_size:int, M:int, alpha_set:list, \n",
    "                 l_rate:float, max_epochs:int, replace, symmetric, saveflag, save_dir, \n",
    "                 alpha_base=None, step=2, device='cuda', verbose=True):\n",
    "        assert 0 < M <= len(model_pool), \"M must be in range (0, len(model_pool)]\"\n",
    "        self.data_loader = data_loader\n",
    "        self.model_pool  = model_pool\n",
    "        self.label_pool  = label_pool  # 与model_pool里每个模型一一对应的模型名字\n",
    "        self.batch_size  = batch_size\n",
    "        self.M           = M           # 最终的集成模型的基学习器个数\n",
    "        self.alpha_set   = alpha_set   # 置信水平集合\n",
    "        self.l_rate      = l_rate      # 学习率\n",
    "        self.max_epochs  = max_epochs\n",
    "        self.device      = device\n",
    "        self.saveflag   = saveflag\n",
    "        self.save_dir    = save_dir\n",
    "        self.alpha_base  = alpha_base if alpha_base else max(alpha_set)\n",
    "        self.quantiles   = [self.alpha_base / 2, 1 - self.alpha_base / 2]\n",
    "        self.loss_fn     = PinballLoss(self.quantiles, self.device)\n",
    "        self.replace     = replace    # 是否有放回地前向选择\n",
    "        self.step        = step       # DMCQR算法更新步长，int, 越小更新越快越准确\n",
    "        self.symmetric   = symmetric  # 是否采用对称性conformity score\n",
    "        # self.logger      = logger\n",
    "        self.verbose     = verbose\n",
    "        \n",
    "    def init_training(self, saveflag=False):\n",
    "        # 先训练好每个基学习器\n",
    "        X_train, Y_train = self.data_loader.get_train_data(to_tensor=True)\n",
    "        X_val  , Y_val   = self.data_loader.get_val_data(to_tensor=True)\n",
    "        # X_train, Y_train = X_train.to(self.device), Y_train.to(self.device)\n",
    "        # X_val  , Y_val   = X_val.to(self.device), Y_val.to(self.device)\n",
    "\n",
    "        assert len(X_train) == len(Y_train)\n",
    "        assert len(X_val)   == len(Y_val)\n",
    "        \n",
    "        print(f'X_train.shape: {X_train.shape}, Y_train.shape: {Y_train.shape}')\n",
    "        print(f'X_val.shape: {X_val.shape}, Y_val.shape: {Y_val.shape}')\n",
    "        # print(f'X_test.shape: {X_test.shape}, Y_train.shape: {Y_test.shape}')\n",
    "\n",
    "        num_models = len(self.model_pool)\n",
    "        model_pool_trained = []\n",
    "        for i, model in enumerate(self.model_pool):\n",
    "            print(f'Model {i+1}/{num_models} {self.label_pool[i]} starts training...')\n",
    "\n",
    "            # 采用DMCQR得到最终的预测区间，则只需要最大的alpha，即两条分位数即可得到多条预测区间上下界。\n",
    "            learner = QuantileRegressionEstimator(model, [max(self.alpha_set)], self.max_epochs,\n",
    "                                                   self.batch_size,self.device, self.l_rate, self.verbose)\n",
    "            learner.fit(X_train, Y_train, X_val, Y_val)\n",
    "            model_pool_trained.append(learner)\n",
    "            print(f'Model {i+1}/{num_models} {self.label_pool[i]} finished training.')\n",
    "            \n",
    "            if saveflag:\n",
    "                torch.save(learner, f'{self.save_dir}/trained_models/{self.label_pool[i]}.pth')\n",
    "                print(f'Model {i+1}/{num_models} saved.')\n",
    "\n",
    "        return model_pool_trained\n",
    "\n",
    "    def forward_selection(self, model_pool_trained, label_pool, replace=True):\n",
    "        # 前向选择出最优集成模型组合\n",
    "        X_val  , Y_val   = self.data_loader.get_val_data(to_tensor=True)\n",
    "        X_val  , Y_val   = X_val.to(self.device), Y_val.to(self.device)\n",
    "        # pool = dict(zip(label_pool, model_pool_trained))\n",
    "        if replace:\n",
    "            print('Forward selection with replacement.')\n",
    "        else:\n",
    "            print('Forward selection without replacement.')\n",
    "\n",
    "        selected_model, selected_label = [], []\n",
    "        while len(selected_model) < self.M:\n",
    "            best_loss = np.inf\n",
    "            \n",
    "            for i in range(len(model_pool_trained)):\n",
    "                models_ = selected_model + [model_pool_trained[i]]\n",
    "                merged_output = torch.stack([torch.from_numpy(model.predict(X_val)) for model in models_])\n",
    "                merged_output = torch.mean(merged_output, axis=0)\n",
    "                loss = self.loss_fn(merged_output, Y_val)\n",
    "                if loss.item() < best_loss:\n",
    "                    best_model = model_pool_trained[i]\n",
    "                    best_loss  = loss.item()\n",
    "                    best_label = i\n",
    "\n",
    "            selected_model.append(best_model)\n",
    "            selected_label.append(label_pool[best_label])\n",
    "            if not replace:  # 无放回\n",
    "                model_pool_trained.pop(best_label)\n",
    "                label_pool.pop(best_label)\n",
    "                \n",
    "        print(f'Model selected: {selected_label}')\n",
    "\n",
    "        return selected_model, selected_label\n",
    "\n",
    "    def conformal(self, res_val, Y_val, res_test, Y_test, step, symmetric=True):\n",
    "        # DMCQR\n",
    "        assert res_val.shape[0] == Y_val.shape[0]\n",
    "        assert res_val.shape[1] == 2\n",
    "        assert res_test.shape[1] == 2\n",
    "\n",
    "        Y_val  , Y_test   = np.array(Y_val),   np.array(Y_test)\n",
    "        res_val, res_test = np.array(res_val), np.array(res_test)\n",
    "        Y_all     = np.concatenate((Y_val, Y_test), axis=0)\n",
    "        res_all   = np.concatenate((res_val, res_test), axis=0)\n",
    "        num_alpha = len(self.alpha_set)\n",
    "        conf_PI   = np.zeros((len(res_test), num_alpha*2))\n",
    "        val_size  = len(Y_val)\n",
    "        test_size = len(Y_test)\n",
    "\n",
    "        if symmetric:  \n",
    "            # DMCQRS, use symmetric conformity score, 对称误差集合\n",
    "            print('Use symmetric conformity score to calibrate quantiles.')\n",
    "            E = list(np.max((res_val[:, 0] - Y_val, Y_val - res_val[:, -1]), axis=0))  # 误差集合，队列，先进先出\n",
    "            Q = np.zeros(num_alpha)\n",
    "\n",
    "            for t in range(val_size, val_size + test_size):\n",
    "                for i, alpha in enumerate(self.alpha_set):\n",
    "                    Q[i] = np.quantile(E, (1-alpha)*(1+1/val_size))\n",
    "                    conf_PI[:, i] = res_test[:, 0] - Q[i]\n",
    "                    conf_PI[:, -(i+1)] = res_test[:, -1] + Q[i]\n",
    "\n",
    "                    if t % step == 0:\n",
    "                        # print(f't = {t}, Q = {Q}')\n",
    "                        for j in range(t - self.step, t - 1):\n",
    "                            e = np.max((res_all[j, 0] - Y_all[j], Y_all[j] - res_all[j, -1]),axis=0)\n",
    "                            E.pop(0)\n",
    "                            E.append(e)   \n",
    "\n",
    "            return conf_PI\n",
    "        \n",
    "        else:   \n",
    "            # DMCQRS, use asymmetric conformity score, 非对称误差集合\n",
    "            print('Use asymmetric conformity score to calibrate quantiles.')\n",
    "            Q_low, Q_high = np.zeros(num_alpha), np.zeros(num_alpha)\n",
    "            E_low = list(res_val[:, 0] - Y_val)    # 下界误差集合\n",
    "            E_high = list(Y_val - res_val[:,-1])   # 上界误差集合\n",
    "                \n",
    "            for t in range(val_size, val_size + test_size):\n",
    "                for i, alpha in enumerate(self.alpha_set):\n",
    "                    Q_low[i] = np.quantile(E_low, (1 - alpha / 2))\n",
    "                    Q_high[-(i+1)] = np.quantile(E_high, (1 - alpha / 2))\n",
    "                    \n",
    "                    conf_PI[:, i] = res_test[:, 0] - Q_low[i]\n",
    "                    conf_PI[:, -(i+1)] = res_test[:, -1] + Q_high[-(i+1)]\n",
    "\n",
    "                if t % step == 0:\n",
    "                    # print(f't: {t}, Q_low: {Q_low}, Q_high: {Q_high}')\n",
    "                    for j in range(t - step, t - 1):\n",
    "                        e_low = res_all[j, 0] - Y_all[j]\n",
    "                        e_high = Y_all[j] - res_all[j, -1]\n",
    "                        E_low.pop(0)\n",
    "                        E_low.append(e_low)\n",
    "                        E_high.pop(0)\n",
    "                        E_high.append(e_high)\n",
    "\n",
    "            return conf_PI     \n",
    "\n",
    "    def fit(self):\n",
    "        self.model_pool_trained = self.init_training()\n",
    "        self.model_pool_selected, self.selected_label = self.forward_selection(self.model_pool_trained, self.label_pool, self.replace)\n",
    "\n",
    "    def predict(self, X_test=None, Y_test=None, inverse_normalization=True):\n",
    "        # construct prediction intervals\n",
    "        X_val  , Y_val   = self.data_loader.get_val_data(to_tensor=True)\n",
    "        if not X_test:\n",
    "            X_test,  Y_test  = self.data_loader.get_test_data(to_tensor=True)\n",
    "        Y_val  , Y_test  = Y_val.detach().numpy(), Y_test.detach().numpy()\n",
    "        X_val   = X_val.to(self.device)\n",
    "        X_test  = X_test.to(self.device)\n",
    "\n",
    "        # pred = self.model_pool_selected[0].predict(X_val)\n",
    "        # print(f'pred.shape: {pred.shape}')\n",
    "        res_val = torch.stack([torch.from_numpy(model.predict(X_val)) for model in self.model_pool_selected])\n",
    "        res_val = torch.mean(res_val, axis=0)\n",
    "        res_val = res_val.detach().numpy()\n",
    "        res_test = torch.stack([torch.from_numpy(model.predict(X_test)) for model in self.model_pool_selected])\n",
    "        res_test = torch.mean(res_test, axis=0)\n",
    "        res_test = res_test.detach().numpy()\n",
    "        # print(f'res_val.shape: {res_val.shape}, res_test.shape: {res_test.shape}')\n",
    "\n",
    "        self.conf_PI = self.conformal(res_val, Y_val, res_test, Y_test, self.step, self.symmetric)\n",
    "        if inverse_normalization:  # 逆标准化回原来的量纲\n",
    "            self.conf_PI = self.data_loader.inverse_transform(self.conf_PI, is_label=True)\n",
    "\n",
    "        cols = [str(round(alpha/2, 3)) for alpha in self.alpha_set] + [str(round(1-alpha/2, 3)) for alpha in reversed(self.alpha_set)]\n",
    "        if self.saveflag:\n",
    "            df = pd.DataFrame(self.conf_PI, columns=cols)\n",
    "            df.to_csv(os.path.join(self.save_dir,'conf_PIs.csv'), index=False)\n",
    "            \n",
    "        return self.conf_PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\\2023_10_10_11_17_09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Postgraduate\\papers\\NESCQR\\code\\NESCQR\\venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BPNN_20', 'RNN_20', 'LSTM_20', 'GRU_20', 'TCN_3']\n"
     ]
    }
   ],
   "source": [
    "# 获取当前时间戳\n",
    "current_time = time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "# 构建文件夹路径\n",
    "save_dir = os.path.join(\"result\", current_time)\n",
    "print(save_dir)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "n_ensemble = 3  #number of baseline models, which is M in paper.\n",
    "M          = n_ensemble\n",
    "max_epochs = 100\n",
    "l_rate     = 1e-4\n",
    "activation = 'tanh'  #nn.Tanh,              nn.ReLU, nn.Sigmoid\n",
    "batch_size = 512\n",
    "dropout    = 0.2\n",
    "replace    = False\n",
    "symmetric  = True\n",
    "saveflag   = True\n",
    "# save_dir   = './results/'\n",
    "step       = 2\n",
    "device     = 'cuda'\n",
    "verbose    = True\n",
    "\n",
    "alpha_set = np.array([0.05, 0.10, 0.15])\n",
    "num_alpha = len(alpha_set)\n",
    "alpha_base = max(alpha_set)\n",
    "quantiles = [max(alpha_set)/2, 1 - max(alpha_set)/2]\n",
    "# quantiles = np.zeros(2*num_alpha)\n",
    "# for i in range(num_alpha):\n",
    "#     quantiles[i] = alpha_set[i] / 2\n",
    "#     quantiles[-(i+1)] = 1 - alpha_set[i] / 2\n",
    "\n",
    "# loss_fn = PinballLoss(quantiles=quantiles, device=device)\n",
    "input_dim = X_train.shape[1]\n",
    "x_size = len(df.columns)\n",
    "out_dim = len(quantiles)\n",
    "kernel_size = 2\n",
    "num_repeat = 1\n",
    "hidden_units = [20 + i*4 for i in range(num_repeat)]\n",
    "channel_sizes = [3 + i*2 for i in range(num_repeat)]\n",
    "\n",
    "model_pool = [NET(input_dim, h, out_dim, activation) for h in hidden_units] + \\\n",
    "             [RNN(input_dim, h, out_dim, activation, device) for h in hidden_units] + \\\n",
    "             [LSTM(input_dim, h, out_dim, device) for h in hidden_units] + \\\n",
    "             [GRU(x_size, h, out_dim, device) for h in hidden_units] + \\\n",
    "             [TCN(x_size, out_dim, [c]*2, kernel_size, dropout) for c in channel_sizes]\n",
    "             \n",
    "# label_pool = ['BPNN']*num_repeat + ['RNN']*num_repeat + ['LSTM']*num_repeat + ['GRU']*num_repeat + ['TCN']*num_repeat\n",
    "label_pool = [f'BPNN_{h}' for h in hidden_units] + \\\n",
    "             [f'RNN_{h}' for h in hidden_units] + \\\n",
    "             [f'LSTM_{h}' for h in hidden_units] + \\\n",
    "             [f'GRU_{h}' for h in hidden_units] + \\\n",
    "             [f'TCN_{c}' for c in channel_sizes]\n",
    "\n",
    "nescqr = NESCQR(loader, model_pool, label_pool, batch_size, M, alpha_set, \n",
    "                 l_rate, max_epochs, replace, symmetric, saveflag, save_dir, alpha_base, step, \n",
    "                  device, verbose)\n",
    "\n",
    "print(label_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: torch.Size([699, 8]), Y_train.shape: torch.Size([699])\n",
      "X_val.shape: torch.Size([149, 8]), Y_val.shape: torch.Size([149])\n",
      "Model 1/5 BPNN_20 starts training...\n",
      "Epoch:100, train_loss: 0.4481, validation_loss: 0.5012, cost_time: 0.02s\n",
      "Model 1/5 BPNN_20 finished training.\n",
      "Model 2/5 RNN_20 starts training...\n",
      "Epoch:100, train_loss: 0.3219, validation_loss: 0.3993, cost_time: 0.02s\n",
      "Model 2/5 RNN_20 finished training.\n",
      "Model 3/5 LSTM_20 starts training...\n",
      "Epoch:100, train_loss: 0.3702, validation_loss: 0.4294, cost_time: 0.01s\n",
      "Model 3/5 LSTM_20 finished training.\n",
      "Model 4/5 GRU_20 starts training...\n",
      "Epoch:100, train_loss: 0.4170, validation_loss: 0.4651, cost_time: 0.02s\n",
      "Model 4/5 GRU_20 finished training.\n",
      "Model 5/5 TCN_3 starts training...\n",
      "Epoch:100, train_loss: 0.5138, validation_loss: 0.6536, cost_time: 0.03s\n",
      "Model 5/5 TCN_3 finished training.\n",
      "Forward selection without replacement.\n",
      "Model selected: ['RNN_20', 'LSTM_20', 'GRU_20']\n",
      "Use symmetric conformity score to calibrate quantiles.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(151, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test , Y_test  = loader.get_test_data(to_tensor=True)\n",
    "nescqr.fit()\n",
    "conf_PI = nescqr.predict()\n",
    "conf_PI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-237.68874139, -123.15764317,  -79.04773945,  837.89391033,\n",
       "        882.00381405,  996.53491227])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_PI[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINC: 95%, MAE: 250.0304, MSE: 91057.0204, RMSE: 301.7566, CRPS: 250.0304, SDE: 298.6288\n",
      "PINC: 95%, PICP: 96.0265, MPIW: 1247.3746, PINAW: 0.9626, F: 0.0016, ACE: 1.0265, CWC: 0.9626,                   interval_score: 1473.1454\n",
      "PINC: 90%, MAE: 250.0304, MSE: 91057.0204, RMSE: 301.7566, CRPS: 250.0304, SDE: 298.6288\n",
      "PINC: 90%, PICP: 92.7152, MPIW: 1018.3124, PINAW: 0.7858, F: 0.0020, ACE: 2.7152, CWC: 0.7858,                   interval_score: 1255.1450\n",
      "PINC: 85%, MAE: 250.0304, MSE: 91057.0204, RMSE: 301.7566, CRPS: 250.0304, SDE: 298.6288\n",
      "PINC: 85%, PICP: 89.4040, MPIW: 930.0926, PINAW: 0.7177, F: 0.0022, ACE: 4.4040, CWC: 0.7177,                   interval_score: 1140.4828\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINC</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>CRPS</th>\n",
       "      <th>SDE</th>\n",
       "      <th>PICP</th>\n",
       "      <th>MPIW</th>\n",
       "      <th>F</th>\n",
       "      <th>PINAW</th>\n",
       "      <th>ACE</th>\n",
       "      <th>CWC</th>\n",
       "      <th>Interval score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.0</td>\n",
       "      <td>250.030378</td>\n",
       "      <td>91057.020361</td>\n",
       "      <td>301.756558</td>\n",
       "      <td>250.030378</td>\n",
       "      <td>298.628832</td>\n",
       "      <td>96.026490</td>\n",
       "      <td>1247.374634</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.962574</td>\n",
       "      <td>1.026490</td>\n",
       "      <td>0.962574</td>\n",
       "      <td>1473.145385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.0</td>\n",
       "      <td>250.030378</td>\n",
       "      <td>91057.020361</td>\n",
       "      <td>301.756558</td>\n",
       "      <td>250.030378</td>\n",
       "      <td>298.628832</td>\n",
       "      <td>92.715232</td>\n",
       "      <td>1018.312437</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.785811</td>\n",
       "      <td>2.715232</td>\n",
       "      <td>0.785811</td>\n",
       "      <td>1255.145046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.0</td>\n",
       "      <td>250.030378</td>\n",
       "      <td>91057.020361</td>\n",
       "      <td>301.756558</td>\n",
       "      <td>250.030378</td>\n",
       "      <td>298.628832</td>\n",
       "      <td>89.403974</td>\n",
       "      <td>930.092630</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.717734</td>\n",
       "      <td>4.403974</td>\n",
       "      <td>0.717734</td>\n",
       "      <td>1140.482809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PINC         MAE           MSE        RMSE        CRPS         SDE  \\\n",
       "0  95.0  250.030378  91057.020361  301.756558  250.030378  298.628832   \n",
       "1  90.0  250.030378  91057.020361  301.756558  250.030378  298.628832   \n",
       "2  85.0  250.030378  91057.020361  301.756558  250.030378  298.628832   \n",
       "\n",
       "        PICP         MPIW         F     PINAW       ACE       CWC  \\\n",
       "0  96.026490  1247.374634  0.001603  0.962574  1.026490  0.962574   \n",
       "1  92.715232  1018.312437  0.001964  0.785811  2.715232  0.785811   \n",
       "2  89.403974   930.092630  0.002150  0.717734  4.403974  0.717734   \n",
       "\n",
       "   Interval score  \n",
       "0     1473.145385  \n",
       "1     1255.145046  \n",
       "2     1140.482809  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_original = loader.inverse_transform(Y_test)\n",
    "res = evaluate(Y_test_original, conf_PI, alpha_set)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cross-bound phenomenon.\n",
      "MUCW = 0.0000, MLCW = 0.0000\n",
      "Cross loss:  0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUCW</th>\n",
       "      <th>MLCW</th>\n",
       "      <th>Cross loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MUCW  MLCW  Cross loss\n",
       "0     0     0         0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cross = cross_bound_check(conf_PI)\n",
    "res_cross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnbPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: torch.Size([699, 8]), Y_train.shape: torch.Size([699])\n",
      "X_val.shape: torch.Size([149, 8]), Y_val.shape: torch.Size([149])\n",
      "X_test.shape: torch.Size([151, 8]), Y_train.shape: torch.Size([151])\n",
      "X_train_enpi.shape: torch.Size([848, 8]), Y_train_enpi.shape: torch.Size([848])\n",
      "-- EnbPI training: 1 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([848, 8]), y_s_b = torch.Size([848, 1]), x_no_s_b.shape = torch.Size([316, 8]), y_no_s_b.shape = torch.Size([316, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Postgraduate\\papers\\NESCQR\\code\\NESCQR\\venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100, train_loss: 1.0757, validation_loss: 0.9045, cost_time: 0.02s\n",
      "model: 1 finished training.\n",
      "-- EnbPI training: 2 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([848, 8]), y_s_b = torch.Size([848, 1]), x_no_s_b.shape = torch.Size([313, 8]), y_no_s_b.shape = torch.Size([313, 1])\n",
      "Epoch:100, train_loss: 0.9396, validation_loss: 0.9948, cost_time: 0.02s\n",
      "model: 2 finished training.\n",
      "-- EnbPI training: 3 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([848, 8]), y_s_b = torch.Size([848, 1]), x_no_s_b.shape = torch.Size([313, 8]), y_no_s_b.shape = torch.Size([313, 1])\n",
      "Epoch:100, train_loss: 1.0038, validation_loss: 0.9345, cost_time: 0.02s\n",
      "model: 3 finished training.\n",
      "-- EnbPI training: 4 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([848, 8]), y_s_b = torch.Size([848, 1]), x_no_s_b.shape = torch.Size([318, 8]), y_no_s_b.shape = torch.Size([318, 1])\n",
      "Epoch:100, train_loss: 0.8260, validation_loss: 0.7725, cost_time: 0.03s\n",
      "model: 4 finished training.\n",
      "-- EnbPI training: 5 of 5 NNs --\n",
      "x_s_b.shape = torch.Size([848, 8]), y_s_b = torch.Size([848, 1]), x_no_s_b.shape = torch.Size([309, 8]), y_no_s_b.shape = torch.Size([309, 1])\n",
      "Epoch:100, train_loss: 1.0650, validation_loss: 1.0313, cost_time: 0.02s\n",
      "model: 5 finished training.\n"
     ]
    }
   ],
   "source": [
    "from algorithms import EnbPI\n",
    "\n",
    "X_train, Y_train = loader.get_train_data(to_tensor=True)\n",
    "X_val  , Y_val   = loader.get_val_data(to_tensor=True)\n",
    "X_test , Y_test  = loader.get_test_data(to_tensor=True)\n",
    "print(f'X_train.shape: {X_train.shape}, Y_train.shape: {Y_train.shape}')\n",
    "print(f'X_val.shape: {X_val.shape}, Y_val.shape: {Y_val.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}, Y_train.shape: {Y_test.shape}')\n",
    "\n",
    "X_train_enpi = torch.cat((X_train, X_val), axis=0)\n",
    "Y_train_enpi = torch.cat((Y_train, Y_val), axis=0)\n",
    "print(f'X_train_enpi.shape: {X_train_enpi.shape}, Y_train_enpi.shape: {Y_train_enpi.shape}')\n",
    "\n",
    "# Define models\n",
    "model_pool_enbpi = [NET(input_dim, h, 1, activation) for h in hidden_units] + \\\n",
    "             [RNN(input_dim, h, 1, activation, device) for h in hidden_units] + \\\n",
    "             [LSTM(input_dim, h, 1, device) for h in hidden_units] + \\\n",
    "             [GRU(x_size, h, 1, device) for h in hidden_units] + \\\n",
    "             [TCN(x_size, 1, [c]*2, kernel_size, dropout) for c in channel_sizes]\n",
    "\n",
    "enbpi = EnbPI(model_pool_enbpi, alpha_set, l_rate, max_epochs, batch_size, device, verbose)\n",
    "enbpi.fit(X_train_enpi, Y_train_enpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conf_PI_enbpi.shape: (151, 6)\n",
      "PINC: 95%, MAE: 230.6093, MSE: 75816.3135, RMSE: 275.3476, CRPS: 230.6093, SDE: 275.2886\n",
      "PINC: 95%, PICP: 98.6755, MPIW: 1420.9276, PINAW: 1.0965, F: 0.0014, ACE: 3.6755, CWC: 1.0965,                   interval_score: 1451.1636\n",
      "PINC: 90%, MAE: 230.6093, MSE: 75816.3135, RMSE: 275.3476, CRPS: 230.6093, SDE: 275.2886\n",
      "PINC: 90%, PICP: 96.6887, MPIW: 1016.9813, PINAW: 0.7848, F: 0.0020, ACE: 6.6887, CWC: 0.7848,                   interval_score: 1118.9812\n",
      "PINC: 85%, MAE: 230.6093, MSE: 75816.3135, RMSE: 275.3476, CRPS: 230.6093, SDE: 275.2886\n",
      "PINC: 85%, PICP: 91.3907, MPIW: 805.3581, PINAW: 0.6215, F: 0.0025, ACE: 6.3907, CWC: 0.6215,                   interval_score: 947.2069\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINC</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>CRPS</th>\n",
       "      <th>SDE</th>\n",
       "      <th>PICP</th>\n",
       "      <th>MPIW</th>\n",
       "      <th>F</th>\n",
       "      <th>PINAW</th>\n",
       "      <th>ACE</th>\n",
       "      <th>CWC</th>\n",
       "      <th>Interval score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.0</td>\n",
       "      <td>230.609263</td>\n",
       "      <td>75816.313483</td>\n",
       "      <td>275.347623</td>\n",
       "      <td>230.609263</td>\n",
       "      <td>275.288584</td>\n",
       "      <td>98.675497</td>\n",
       "      <td>1420.927611</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>1.096501</td>\n",
       "      <td>3.675497</td>\n",
       "      <td>1.096501</td>\n",
       "      <td>1451.163562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.0</td>\n",
       "      <td>230.609263</td>\n",
       "      <td>75816.313483</td>\n",
       "      <td>275.347623</td>\n",
       "      <td>230.609263</td>\n",
       "      <td>275.288584</td>\n",
       "      <td>96.688742</td>\n",
       "      <td>1016.981342</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.784784</td>\n",
       "      <td>6.688742</td>\n",
       "      <td>0.784784</td>\n",
       "      <td>1118.981241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.0</td>\n",
       "      <td>230.609263</td>\n",
       "      <td>75816.313483</td>\n",
       "      <td>275.347623</td>\n",
       "      <td>230.609263</td>\n",
       "      <td>275.288584</td>\n",
       "      <td>91.390728</td>\n",
       "      <td>805.358087</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.621479</td>\n",
       "      <td>6.390728</td>\n",
       "      <td>0.621479</td>\n",
       "      <td>947.206893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PINC         MAE           MSE        RMSE        CRPS         SDE  \\\n",
       "0  95.0  230.609263  75816.313483  275.347623  230.609263  275.288584   \n",
       "1  90.0  230.609263  75816.313483  275.347623  230.609263  275.288584   \n",
       "2  85.0  230.609263  75816.313483  275.347623  230.609263  275.288584   \n",
       "\n",
       "        PICP         MPIW         F     PINAW       ACE       CWC  \\\n",
       "0  98.675497  1420.927611  0.001408  1.096501  3.675497  1.096501   \n",
       "1  96.688742  1016.981342  0.001967  0.784784  6.688742  0.784784   \n",
       "2  91.390728   805.358087  0.002483  0.621479  6.390728  0.621479   \n",
       "\n",
       "   Interval score  \n",
       "0     1451.163562  \n",
       "1     1118.981241  \n",
       "2      947.206893  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_PI_enbpi = enbpi.predict_interval(X_train_enpi, Y_train_enpi, X_test, Y_test, step)\n",
    "conf_PI_enbpi = loader.inverse_transform(conf_PI_enbpi, is_label=True)\n",
    "print(f'conf_PI_enbpi.shape: {conf_PI_enbpi.shape}')\n",
    "\n",
    "res_enbpi = evaluate(Y_test_original, conf_PI_enbpi, alpha_set)\n",
    "res_enbpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cross-bound phenomenon.\n",
      "MUCW = 0.0000, MLCW = 0.0000\n",
      "Cross loss:  0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUCW</th>\n",
       "      <th>MLCW</th>\n",
       "      <th>Cross loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MUCW  MLCW  Cross loss\n",
       "0     0     0         0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_bound_check(conf_PI_enbpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EnCQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EnCQR():\n",
    "#     def __init__(self, model_pool, alpha_set, l_rate:float, max_epochs:int, batch_size:int, device='cuda', verbose=True):\n",
    "\n",
    "#         self.n_ensemble = len(model_pool)  #基学习器数量\n",
    "#         self.NNs = model_pool\n",
    "#         self.l_rate = l_rate  #学习率\n",
    "#         self.max_epochs = max_epochs\n",
    "#         self.batch_size = batch_size  #越大更新越慢，int.\n",
    "#         self.device = device\n",
    "#         self.verbose = verbose  #是否输出中间过程\n",
    "#         self.alpha_set = alpha_set\n",
    "#         self.num_alpha = len(alpha_set)\n",
    "\n",
    "#     def fit(self, X_train, Y_train):\n",
    "    \n",
    "#         T = X_train.shape[0]\n",
    "#         tb = int(np.floor(T / self.n_ensemble))\n",
    "\n",
    "#         S = np.arange(0, T)\n",
    "#         for b in range(self.n_ensemble):\n",
    "#             print('-- EnCQR training: ' + str(b+1) + ' of ' + str(self.n_ensemble) + ' NNs --')\n",
    "\n",
    "#             s_b = range(tb*b, (tb*b+tb))\n",
    "#             no_s_b = np.delete(S, s_b, 0)\n",
    "#             x_s_b, y_s_b = X_train[s_b, :], Y_train[s_b].reshape(len(s_b), 1)\n",
    "\n",
    "#             x_no_s_b = X_train[no_s_b, :]\n",
    "#             y_no_s_b = Y_train[no_s_b].reshape(len(no_s_b), 1)\n",
    "\n",
    "#             if self.verbose:\n",
    "#                 print(f'x_s_b.shape = {x_s_b.shape}, y_s_b = {y_s_b.shape}, x_no_s_b.shape = {x_no_s_b.shape}, y_no_s_b.shape = {y_no_s_b.shape}')\n",
    "\n",
    "#             learner = QuantileRegressionEstimator(self.NNs[b], self.alpha_set, self.max_epochs, self.batch_size,\\\n",
    "#                                                    self.device, self.l_rate, self.verbose)\n",
    "#             learner.fit(x_s_b, y_s_b, x_no_s_b, y_no_s_b)\n",
    "#             print('Model: %d finished training.' % (b+1))  \n",
    "        \n",
    "#         self.no_s_b = no_s_b\n",
    "\n",
    "#     def predict(self, x):\n",
    "#         '''\n",
    "#         分位数预测。Quantile regression.\n",
    "\n",
    "#         out:\n",
    "#         res: point forecasting results of x, ndarray, [N, ].\n",
    "#         '''\n",
    "#         n_ensemble = len(self.NNs)\n",
    "#         P = torch.zeros(n_ensemble, x.shape[0], self.num_alpha*2)\n",
    "\n",
    "#         for b in range(n_ensemble):\n",
    "\n",
    "#             model = self.NNs[b]\n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 x = x.to(self.device)\n",
    "#                 pred = model(x)\n",
    "            \n",
    "#             P[b, :, :] = pred.to(torch.float32)\n",
    "        \n",
    "#         res = P.mean(axis=0)\n",
    "#         res = res.numpy()\n",
    "#         res = res.squeeze()\n",
    "\n",
    "#         return res\n",
    "\n",
    "#     def predict_interval(self, X_train, Y_train, X_test, Y_test, step=None):\n",
    "#         '''\n",
    "#         区间预测。Interval prediction. fit完直接就可以调用来构造预测区间。\n",
    "        \n",
    "#         out:\n",
    "#         C: prediction intervals.\n",
    "#         '''\n",
    "        \n",
    "#         Y_train, Y_test = np.array(Y_train), np.array(Y_test)\n",
    "\n",
    "#         res_train = self.predict(X_train)\n",
    "#         res_test = self.predict(X_test)\n",
    "#         T1 = res_test.shape[0]\n",
    "#         if step == None:\n",
    "#             step = self.batch_size\n",
    "\n",
    "#         # Initialize the asymmetric conformity scores.\n",
    "#         C = np.zeros((T1, self.num_alpha*2))\n",
    "#         E_low, E_high = np.zeros((len(self.no_s_b), self.num_alpha)), np.zeros((len(self.no_s_b), self.num_alpha))\n",
    "#         Q_low, Q_high = np.zeros((self.num_alpha,)), np.zeros((self.num_alpha,))\n",
    "#         for i in range(self.num_alpha):\n",
    "#             E_low[:, i] = (res_train[self.no_s_b, i].reshape((len(self.no_s_b),1)) - Y_train[self.no_s_b].reshape((len(self.no_s_b),1))).squeeze()\n",
    "#             E_high[:, -(i+1)] = (Y_train[self.no_s_b].reshape((len(self.no_s_b),1)) - res_train[self.no_s_b, -(i+1)].reshape((len(self.no_s_b),1))).squeeze()\n",
    "\n",
    "#         # Comformalize the prediction intervals.\n",
    "#         for t in range(T1):\n",
    "#             for i, alpha in enumerate(self.alpha_set):\n",
    "                \n",
    "#                 Q_low[i] = np.quantile(E_low[:, i], 1 - alpha / 2)\n",
    "#                 Q_high[-(i+1)] = np.quantile(E_high[:, -(i+1)], 1 - alpha / 2)\n",
    "\n",
    "#                 C[t, i] = res_test[t, i] - Q_low[i]\n",
    "#                 C[t, -(i+1)] = res_test[t, -(i+1)] + Q_high[-(i+1)]\n",
    "\n",
    "#             # Update the lists of conformity scores\n",
    "#             if t % step == 0 and step < T1:\n",
    "#                 # print('t = %d, Q_low[0] = %f, Q_high[-1] = %f, E_low.shape = %s, E_high.shape = %s.' % \n",
    "#                 #   (t,Q_low[0],Q_high[-1],str(E_low.shape), str(E_high.shape)))\n",
    "#                 for j in range(t - step, t-1):\n",
    "#                     for i in range(self.num_alpha):\n",
    "#                         e_low = res_test[j, i] - Y_test[j]\n",
    "#                         e_high = Y_test[j] - res_test[j, -(i+1)]\n",
    "#                         E_low_temp = np.delete(E_low[:,i], 0, 0)    #删除第一个元素\n",
    "#                         E_low_temp = np.append(E_low_temp, e_low)   #添加新的元素\n",
    "#                         E_low[:,i] = E_low_temp\n",
    "#                         E_high_temp = np.delete(E_high[:,-(i+1)], 0, 0)\n",
    "#                         E_high_temp = np.append(E_high_temp, e_high)\n",
    "#                         E_high[:,-(i+1)] = E_high_temp   \n",
    "\n",
    "#         return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import asym_nonconformity\n",
    "\n",
    "class EnCQR:\n",
    "    def __init__(self, model_pool, alpha_set, step, batch_size, l_rate, max_epochs, device, verbose):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_data : list of data to train an ensemble of models\n",
    "        test_x : input test data\n",
    "        test_y : output test data\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        PI : original PI produced by the ensemble model\n",
    "        conf_PI : PI after the conformalization\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_pool = model_pool\n",
    "        self.alpha_set  = alpha_set\n",
    "        self.num_alpha  = len(alpha_set)\n",
    "        self.step       = step\n",
    "        self.batch_size = batch_size\n",
    "        self.l_rate     = l_rate\n",
    "        self.max_epochs = max_epochs\n",
    "        self.device     = device\n",
    "        self.verbose    = verbose\n",
    "\n",
    "    def fit(self, train_data, val_x, val_y):\n",
    "        \"\"\"\n",
    "        Train models.\n",
    "\n",
    "        Args:\n",
    "        train_data: list, [[x1, y1], [x2, y2], ...]\n",
    "        val_x: input validation data\n",
    "        val_y: output validation data\n",
    "        \"\"\"\n",
    "\n",
    "        B = len(self.model_pool)\n",
    "        index = np.arange(B)\n",
    "        num_alpha = len(self.alpha_set)\n",
    "    \n",
    "        # dict containing LOO predictions\n",
    "        dct_lo = {}\n",
    "        dct_hi = {}\n",
    "        for key in index:\n",
    "            dct_lo['pred_%s' % key] = []\n",
    "            dct_hi['pred_%s' % key] = []\n",
    "        \n",
    "        # training a model for each sub set Sb\n",
    "        self.ensemble_models = []\n",
    "        half = len(self.alpha_set)  # number of the alpha_set\n",
    "        for b in range(B):\n",
    "            print(f'-- EnCQR training: {b+1}/{B} NNs --')\n",
    "            x, y = train_data[b][0], train_data[b][1]\n",
    "            # print(f'b: {b}, x.shape: {x.shape}, y.shape: {y.shape}')\n",
    "            learner = QuantileRegressionEstimator(self.model_pool[b], self.alpha_set, self.max_epochs, \\\n",
    "                                                  self.batch_size, self.device, self.l_rate, self.verbose)\n",
    "            learner.fit(x, y, val_x, val_y)\n",
    "            self.ensemble_models.append(learner)\n",
    "            # print(f'b: learner.quantiles: {learner.quantiles}')\n",
    "            \n",
    "            # Leave-one-out predictions for each Sb, TERRIBLE\n",
    "            # 在小样本上训练的模型去预测剩下的未见过的大样本，分位数表现非常糟糕\n",
    "            indx_LOO = index[np.arange(len(index))!=b]\n",
    "            print(f'b: {b}, indx_LOO: {indx_LOO}')\n",
    "            for i in range(len(indx_LOO)):\n",
    "                x_ = train_data[indx_LOO[i]][0]\n",
    "                # print(f'b: {b}, i: {i}, indx_LOO[i]: {indx_LOO[i]}, x_.shape: {x_.shape}')\n",
    "                pred = learner.predict(x_)\n",
    "                # print(f'i: {i}, pred.mean: {pred.mean(axis=0)}')\n",
    "                dct_lo['pred_%s' %indx_LOO[i]].append(pred[:, :half])\n",
    "                dct_hi['pred_%s' %indx_LOO[i]].append(pred[:, half:])\n",
    "\n",
    "        f_hat_b_agg_low  = np.zeros((train_data[index[0]][0].shape[0], half, B))\n",
    "        f_hat_b_agg_high = np.zeros((train_data[index[0]][0].shape[0], half, B))\n",
    "        for b in range(B):\n",
    "            f_hat_b_agg_low[:,:,b] = np.mean(dct_lo['pred_%s' %b],axis=0) \n",
    "            f_hat_b_agg_high[:,:,b] = np.mean(dct_hi['pred_%s' %b],axis=0)  \n",
    "            \n",
    "        print(f'f_hat_b_agg_low.shape: {f_hat_b_agg_low.shape}, mean: {f_hat_b_agg_low.mean(axis=0)}')\n",
    "        # residuals on the training data\n",
    "        E_low, E_high = [], []\n",
    "        for i in range(self.num_alpha):\n",
    "            epsilon_low, epsilon_hi = [], []\n",
    "            for b in range(B):\n",
    "                e_low, e_high = asym_nonconformity(label=train_data[b][1].detach().numpy(), \n",
    "                                                        low=f_hat_b_agg_low[:,i,b], \n",
    "                                                        high=f_hat_b_agg_high[:,i,b])\n",
    "                epsilon_low.append(e_low)\n",
    "                epsilon_hi.append(e_high)\n",
    "            E_low.append(epsilon_low)\n",
    "            E_high.append(epsilon_hi)\n",
    "        self.E_low = np.array(E_low)\n",
    "        self.E_low = self.E_low.reshape(self.E_low.shape[1]*self.E_low.shape[2], self.num_alpha)\n",
    "        self.E_high = np.array(E_high)\n",
    "        self.E_high = self.E_high.reshape(self.E_high.shape[1]*self.E_high.shape[2], self.num_alpha)\n",
    "        # print(f'E_low.shape: {self.E_low.shape}, E_high.shape: {self.E_high.shape}')\n",
    "        # print(f'E_low.mean: {self.E_low.mean(axis=0)}, E_high.mean: {self.E_high.mean(axis=0)}')\n",
    "        print('EnCQR training is done.')\n",
    "\n",
    "    def predict(self, test_x, test_y, step=None):\n",
    "\n",
    "        # PI\n",
    "        res_test = np.zeros((len(self.ensemble_models), test_y.shape[0], len(self.alpha_set)*2))\n",
    "        for i, model in enumerate(self.ensemble_models):\n",
    "            pred = model.predict(test_x)\n",
    "            print(f'pred.shape: {pred.shape}')\n",
    "            res_test[i, :, :] = model.predict(test_x)\n",
    "\n",
    "        res_test = np.mean(res_test, axis=0)\n",
    "        # print(f'res_test.shape: {res_test.shape}')\n",
    "        # print(f'res_test.mean: {res_test.mean(axis=0)}')\n",
    "        \n",
    "        # Conformal\n",
    "        test_size = res_test.shape[0]\n",
    "        if step == None:\n",
    "            step = self.step\n",
    "\n",
    "        # Initialize the asymmetric conformity scores.\n",
    "        C = np.zeros((test_size, self.num_alpha*2))\n",
    "        Q_low, Q_high = np.zeros((self.num_alpha,)), np.zeros((self.num_alpha,))\n",
    "\n",
    "        # Comformalize the prediction intervals.\n",
    "        for t in range(test_size):\n",
    "            for i, alpha in enumerate(self.alpha_set):\n",
    "                \n",
    "                Q_low[i] = np.quantile(self.E_low[:, i], 1 - alpha / 2)\n",
    "                Q_high[-(i+1)] = np.quantile(self.E_high[:, -(i+1)], 1 - alpha / 2)\n",
    "\n",
    "                C[t, i] = res_test[t, i] - Q_low[i]\n",
    "                C[t, -(i+1)] = res_test[t, -(i+1)] + Q_high[-(i+1)]\n",
    "\n",
    "            # Update the lists of conformity scores\n",
    "            if t % step == 0 and step < test_size:\n",
    "                # print('t = %d, Q_low[0] = %f, Q_high[-1] = %f, E_low.shape = %s, E_high.shape = %s.' % \n",
    "                #   (t,Q_low[0],Q_high[-1],str(E_low.shape), str(E_high.shape)))\n",
    "                for j in range(t - step, t-1):\n",
    "                    for i in range(self.num_alpha):\n",
    "                        e_low = res_test[j, i] - test_y[j]\n",
    "                        e_high = test_y[j] - res_test[j, -(i+1)]\n",
    "                        E_low_temp = np.delete(self.E_low[:,i], 0, 0)    #删除第一个元素\n",
    "                        E_low_temp = np.append(E_low_temp, e_low)   #添加新的元素\n",
    "                        self.E_low[:,i] = E_low_temp\n",
    "                        E_high_temp = np.delete(self.E_high[:,-(i+1)], 0, 0)\n",
    "                        E_high_temp = np.append(E_high_temp, e_high)\n",
    "                        self.E_high[:,-(i+1)] = E_high_temp   \n",
    "\n",
    "        return res_test, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Postgraduate\\papers\\NESCQR\\code\\NESCQR\\venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = torch.Size([699, 8])\n",
      "0 139\n",
      "b: 0, batch_len: 139, b*batch_len:0, (b+1)*batch_len-to_del: 139\n",
      "b: 1, batch_len: 139, b*batch_len:139, (b+1)*batch_len-to_del: 278\n",
      "b: 2, batch_len: 139, b*batch_len:278, (b+1)*batch_len-to_del: 417\n",
      "b: 3, batch_len: 139, b*batch_len:417, (b+1)*batch_len-to_del: 556\n",
      "b: 4, batch_len: 139, b*batch_len:556, (b+1)*batch_len-to_del: 695\n",
      "5\n",
      "-- EnCQR training: 1/5 NNs --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:100, train_loss: 0.3441, validation_loss: 0.4145, cost_time: 0.01s\n",
      "Epoch:200, train_loss: 0.3068, validation_loss: 0.3854, cost_time: 0.01s\n",
      "b: 0, indx_LOO: [1 2 3 4]\n",
      "b: 0, i: 0, indx_LOO[i]: 1, x_.shape: torch.Size([139, 8])\n",
      "b: 0, i: 1, indx_LOO[i]: 2, x_.shape: torch.Size([139, 8])\n",
      "b: 0, i: 2, indx_LOO[i]: 3, x_.shape: torch.Size([139, 8])\n",
      "b: 0, i: 3, indx_LOO[i]: 4, x_.shape: torch.Size([139, 8])\n",
      "-- EnCQR training: 2/5 NNs --\n",
      "Epoch:100, train_loss: 0.3488, validation_loss: 0.3896, cost_time: 0.01s\n",
      "Epoch:200, train_loss: 0.3123, validation_loss: 0.3594, cost_time: 0.01s\n",
      "b: 1, indx_LOO: [0 2 3 4]\n",
      "b: 1, i: 0, indx_LOO[i]: 0, x_.shape: torch.Size([139, 8])\n",
      "b: 1, i: 1, indx_LOO[i]: 2, x_.shape: torch.Size([139, 8])\n",
      "b: 1, i: 2, indx_LOO[i]: 3, x_.shape: torch.Size([139, 8])\n",
      "b: 1, i: 3, indx_LOO[i]: 4, x_.shape: torch.Size([139, 8])\n",
      "-- EnCQR training: 3/5 NNs --\n",
      "Epoch:100, train_loss: 0.3793, validation_loss: 0.4089, cost_time: 0.01s\n",
      "Epoch:200, train_loss: 0.3624, validation_loss: 0.3972, cost_time: 0.01s\n",
      "b: 2, indx_LOO: [0 1 3 4]\n",
      "b: 2, i: 0, indx_LOO[i]: 0, x_.shape: torch.Size([139, 8])\n",
      "b: 2, i: 1, indx_LOO[i]: 1, x_.shape: torch.Size([139, 8])\n",
      "b: 2, i: 2, indx_LOO[i]: 3, x_.shape: torch.Size([139, 8])\n",
      "b: 2, i: 3, indx_LOO[i]: 4, x_.shape: torch.Size([139, 8])\n",
      "-- EnCQR training: 4/5 NNs --\n",
      "Epoch:100, train_loss: 0.3745, validation_loss: 0.4347, cost_time: 0.01s\n",
      "Epoch:200, train_loss: 0.3472, validation_loss: 0.4102, cost_time: 0.01s\n",
      "b: 3, indx_LOO: [0 1 2 4]\n",
      "b: 3, i: 0, indx_LOO[i]: 0, x_.shape: torch.Size([139, 8])\n",
      "b: 3, i: 1, indx_LOO[i]: 1, x_.shape: torch.Size([139, 8])\n",
      "b: 3, i: 2, indx_LOO[i]: 2, x_.shape: torch.Size([139, 8])\n",
      "b: 3, i: 3, indx_LOO[i]: 4, x_.shape: torch.Size([139, 8])\n",
      "-- EnCQR training: 5/5 NNs --\n",
      "Epoch:100, train_loss: 0.3299, validation_loss: 0.3719, cost_time: 0.02s\n",
      "Epoch:200, train_loss: 0.3137, validation_loss: 0.3566, cost_time: 0.01s\n",
      "b: 4, indx_LOO: [0 1 2 3]\n",
      "b: 4, i: 0, indx_LOO[i]: 0, x_.shape: torch.Size([139, 8])\n",
      "b: 4, i: 1, indx_LOO[i]: 1, x_.shape: torch.Size([139, 8])\n",
      "b: 4, i: 2, indx_LOO[i]: 2, x_.shape: torch.Size([139, 8])\n",
      "b: 4, i: 3, indx_LOO[i]: 3, x_.shape: torch.Size([139, 8])\n",
      "f_hat_b_agg_low.shape: (139, 3, 5), mean: [[-0.17818636 -0.17594716 -0.19767646 -0.22376274 -0.07203565]\n",
      " [-0.06100817  0.08320673  0.03992651 -0.00153851 -0.19512106]\n",
      " [-0.20690767 -0.22564832 -0.20912002 -0.19275683 -0.04720564]]\n",
      "EnCQR training is done.\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "# alpha_set_encqr = [0.1]\n",
    "alpha_set_encqr = alpha_set\n",
    "out_dim_encqr = len(alpha_set_encqr) * 2\n",
    "model_pool_encqr = [NET(input_dim, h, out_dim_encqr, activation) for h in hidden_units] + \\\n",
    "             [RNN(input_dim, h, out_dim_encqr, activation, device) for h in hidden_units] + \\\n",
    "             [LSTM(input_dim, h, out_dim_encqr, device) for h in hidden_units] + \\\n",
    "             [GRU(x_size, h, out_dim_encqr, device) for h in hidden_units] + \\\n",
    "             [TCN(x_size, out_dim_encqr, [c]*2, kernel_size, dropout) for c in channel_sizes]\n",
    "\n",
    "time_steps_in=24\n",
    "time_steps_out=6\n",
    "\n",
    "B = len(model_pool_encqr)\n",
    "batch_len = int(np.floor(X_train.shape[0]/B))\n",
    "# to_del = time_steps_in//time_steps_out # make sure there are no overlapping windows across batches\n",
    "to_del = 0\n",
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(to_del, batch_len)\n",
    "\n",
    "train_data = []\n",
    "for b in range(len(model_pool_encqr)):\n",
    "    print(f'b: {b}, batch_len: {batch_len}, b*batch_len:{b*batch_len}, (b+1)*batch_len-to_del: {(b+1)*batch_len-to_del}')\n",
    "    train_data.append([X_train[b*batch_len:(b+1)*batch_len-to_del], Y_train[b*batch_len:(b+1)*batch_len-to_del]])\n",
    "    \n",
    "print(len(train_data))\n",
    "\n",
    "max_epochs_encqr = 200\n",
    "encqr = EnCQR(model_pool_encqr, alpha_set_encqr, step, batch_size, l_rate, max_epochs_encqr, device, verbose)\n",
    "encqr.fit(train_data, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred.shape: (151, 6)\n",
      "pred.shape: (151, 6)\n",
      "pred.shape: (151, 6)\n",
      "pred.shape: (151, 6)\n",
      "pred.shape: (151, 6)\n",
      "conf_PI_encqr.shape: (151, 6)\n",
      "PINC: 95%, MAE: 284.6974, MSE: 115419.2395, RMSE: 339.7341, CRPS: 284.6974, SDE: 292.4923\n",
      "PINC: 95%, PICP: 99.3377, MPIW: 1329.8381, PINAW: 1.0262, F: 0.0015, ACE: 4.3377, CWC: 1.0262,                   interval_score: 1330.9188\n",
      "PINC: 90%, MAE: 273.1011, MSE: 107079.1513, RMSE: 327.2295, CRPS: 273.1011, SDE: 291.7999\n",
      "PINC: 90%, PICP: 96.0265, MPIW: 1120.5914, PINAW: 0.8647, F: 0.0018, ACE: 6.0265, CWC: 0.8647,                   interval_score: 1154.8223\n",
      "PINC: 85%, MAE: 233.7237, MSE: 77171.6341, RMSE: 277.7978, CRPS: 233.7237, SDE: 274.5907\n",
      "PINC: 85%, PICP: 96.6887, MPIW: 962.3339, PINAW: 0.7426, F: 0.0021, ACE: 11.6887, CWC: 0.7426,                   interval_score: 1021.3419\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINC</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>CRPS</th>\n",
       "      <th>SDE</th>\n",
       "      <th>PICP</th>\n",
       "      <th>MPIW</th>\n",
       "      <th>F</th>\n",
       "      <th>PINAW</th>\n",
       "      <th>ACE</th>\n",
       "      <th>CWC</th>\n",
       "      <th>Interval score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.0</td>\n",
       "      <td>284.697375</td>\n",
       "      <td>115419.239541</td>\n",
       "      <td>339.734072</td>\n",
       "      <td>284.697375</td>\n",
       "      <td>292.492320</td>\n",
       "      <td>99.337748</td>\n",
       "      <td>1329.838079</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>1.026210</td>\n",
       "      <td>4.337748</td>\n",
       "      <td>1.026210</td>\n",
       "      <td>1330.918785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.0</td>\n",
       "      <td>273.101081</td>\n",
       "      <td>107079.151264</td>\n",
       "      <td>327.229509</td>\n",
       "      <td>273.101081</td>\n",
       "      <td>291.799875</td>\n",
       "      <td>96.026490</td>\n",
       "      <td>1120.591359</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.864738</td>\n",
       "      <td>6.026490</td>\n",
       "      <td>0.864738</td>\n",
       "      <td>1154.822341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85.0</td>\n",
       "      <td>233.723728</td>\n",
       "      <td>77171.634077</td>\n",
       "      <td>277.797830</td>\n",
       "      <td>233.723728</td>\n",
       "      <td>274.590671</td>\n",
       "      <td>96.688742</td>\n",
       "      <td>962.333909</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.742614</td>\n",
       "      <td>11.688742</td>\n",
       "      <td>0.742614</td>\n",
       "      <td>1021.341939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PINC         MAE            MSE        RMSE        CRPS         SDE  \\\n",
       "0  95.0  284.697375  115419.239541  339.734072  284.697375  292.492320   \n",
       "1  90.0  273.101081  107079.151264  327.229509  273.101081  291.799875   \n",
       "2  85.0  233.723728   77171.634077  277.797830  233.723728  274.590671   \n",
       "\n",
       "        PICP         MPIW         F     PINAW        ACE       CWC  \\\n",
       "0  99.337748  1329.838079  0.001504  1.026210   4.337748  1.026210   \n",
       "1  96.026490  1120.591359  0.001785  0.864738   6.026490  0.864738   \n",
       "2  96.688742   962.333909  0.002078  0.742614  11.688742  0.742614   \n",
       "\n",
       "   Interval score  \n",
       "0     1330.918785  \n",
       "1     1154.822341  \n",
       "2     1021.341939  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PI_encqr, conf_PI_encqr = encqr.predict(X_test, Y_test)\n",
    "print(f'conf_PI_encqr.shape: {conf_PI_encqr.shape}')\n",
    "\n",
    "conf_PI_encqr = loader.inverse_transform(conf_PI_encqr, is_label=True)\n",
    "\n",
    "res_encqr = evaluate(Y_test_original, conf_PI_encqr, alpha_set_encqr)\n",
    "res_encqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -68.87225295,   11.0235057 ,  -15.8519336 ,  946.48197527,\n",
       "       1131.61486491, 1260.96582629])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_PI_encqr.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-bound phenomenon exists.\n",
      "l.sum() =  120.0\n",
      "u.sum() =  0.0\n",
      "MUCW = 0.0000, MLCW = 36.2124\n",
      "Cross loss:  28.778033424833914\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MUCW</th>\n",
       "      <th>MLCW</th>\n",
       "      <th>Cross loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36.212359</td>\n",
       "      <td>28.778033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MUCW       MLCW  Cross loss\n",
       "0     0  36.212359   28.778033"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_bound_check(conf_PI_encqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([139, 8])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[b*batch_len:(b+1)*batch_len-to_del].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([139, 8]), torch.Size([139]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_data[0]))\n",
    "train_data[0][0].shape, train_data[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: [0 1 2 3 4]\n",
      "index[b]: 0\n",
      "indx_LOO: [1 2 3 4]\n",
      "index[b]: 1\n",
      "indx_LOO: [0 2 3 4]\n",
      "index[b]: 2\n",
      "indx_LOO: [0 1 3 4]\n",
      "index[b]: 3\n",
      "indx_LOO: [0 1 2 4]\n",
      "index[b]: 4\n",
      "indx_LOO: [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "B = len(model_pool_encqr)\n",
    "index = np.arange(B)\n",
    "print(f'index: {index}')\n",
    "for b in range(B):\n",
    "    print(f'index[b]: {index[b]}')\n",
    "    indx_LOO = index[np.arange(len(index))!=b]\n",
    "    print(f'indx_LOO: {indx_LOO}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
